{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling as pp\n",
    "import math\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# preprocessing\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, learning_curve, ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_predict as cvp\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, accuracy_score, confusion_matrix, explained_variance_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, RFE, chi2\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Perceptron, RidgeClassifier, SGDClassifier, LassoCV\n",
    "from sklearn.svm import SVC, LinearSVC, SVR\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier \n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# NN models\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pytorch_tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('float_format', '{:f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d.barcode</th>\n",
       "      <th>DP</th>\n",
       "      <th>VD</th>\n",
       "      <th>AF</th>\n",
       "      <th>HIAF</th>\n",
       "      <th>IMPACT</th>\n",
       "      <th>SYMBOL</th>\n",
       "      <th>loci</th>\n",
       "      <th>sampleTimePt</th>\n",
       "      <th>gender</th>\n",
       "      <th>MSID</th>\n",
       "      <th>BIAS</th>\n",
       "      <th>REFBIAS</th>\n",
       "      <th>VARBIAS</th>\n",
       "      <th>QUAL</th>\n",
       "      <th>ODDRATIO</th>\n",
       "      <th>chipOrControl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4010289633</td>\n",
       "      <td>7281</td>\n",
       "      <td>26</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>MODERATE</td>\n",
       "      <td>GNB1</td>\n",
       "      <td>chr1:1747196_T/C</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>Male</td>\n",
       "      <td>MS2083</td>\n",
       "      <td>2:2</td>\n",
       "      <td>3644:3596</td>\n",
       "      <td>12:14</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.182210</td>\n",
       "      <td>CHIP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4010289633</td>\n",
       "      <td>7281</td>\n",
       "      <td>26</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>MODERATE</td>\n",
       "      <td>GNB1</td>\n",
       "      <td>chr1:1747196_T/C</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>Male</td>\n",
       "      <td>MS2083</td>\n",
       "      <td>2:2</td>\n",
       "      <td>3644:3596</td>\n",
       "      <td>12:14</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.182210</td>\n",
       "      <td>CHIP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4010289633</td>\n",
       "      <td>7281</td>\n",
       "      <td>26</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>MODERATE</td>\n",
       "      <td>GNB1</td>\n",
       "      <td>chr1:1747196_T/C</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>Male</td>\n",
       "      <td>MS2083</td>\n",
       "      <td>2:2</td>\n",
       "      <td>3644:3596</td>\n",
       "      <td>12:14</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.182210</td>\n",
       "      <td>CHIP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4010289633</td>\n",
       "      <td>7281</td>\n",
       "      <td>26</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>MODERATE</td>\n",
       "      <td>GNB1</td>\n",
       "      <td>chr1:1747196_T/C</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>Male</td>\n",
       "      <td>MS2083</td>\n",
       "      <td>2:2</td>\n",
       "      <td>3644:3596</td>\n",
       "      <td>12:14</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.182210</td>\n",
       "      <td>CHIP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4010289633</td>\n",
       "      <td>7282</td>\n",
       "      <td>29</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>MODERATE</td>\n",
       "      <td>GNB1</td>\n",
       "      <td>chr1:1747250_T/C</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>Male</td>\n",
       "      <td>MS2083</td>\n",
       "      <td>2:2</td>\n",
       "      <td>3639:3606</td>\n",
       "      <td>15:14</td>\n",
       "      <td>32.700000</td>\n",
       "      <td>1.061729</td>\n",
       "      <td>CHIP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137944</th>\n",
       "      <td>4010290016</td>\n",
       "      <td>731</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>MODERATE</td>\n",
       "      <td>ZFY</td>\n",
       "      <td>chrY:2848011_C/T</td>\n",
       "      <td>Blank</td>\n",
       "      <td>Blank</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2:2</td>\n",
       "      <td>371:357</td>\n",
       "      <td>1:1</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.039170</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137945</th>\n",
       "      <td>4010290016</td>\n",
       "      <td>731</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>MODERATE</td>\n",
       "      <td>ZFY</td>\n",
       "      <td>chrY:2848029_C/T</td>\n",
       "      <td>Blank</td>\n",
       "      <td>Blank</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2:2</td>\n",
       "      <td>367:359</td>\n",
       "      <td>1:1</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.022260</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137946</th>\n",
       "      <td>4010290016</td>\n",
       "      <td>731</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>MODERATE</td>\n",
       "      <td>ZFY</td>\n",
       "      <td>chrY:2848029_C/T</td>\n",
       "      <td>Blank</td>\n",
       "      <td>Blank</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2:2</td>\n",
       "      <td>367:359</td>\n",
       "      <td>1:1</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.022260</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137947</th>\n",
       "      <td>4010290016</td>\n",
       "      <td>731</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>MODERATE</td>\n",
       "      <td>ZFY</td>\n",
       "      <td>chrY:2848029_C/T</td>\n",
       "      <td>Blank</td>\n",
       "      <td>Blank</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2:2</td>\n",
       "      <td>367:359</td>\n",
       "      <td>1:1</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.022260</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137948</th>\n",
       "      <td>4010290016</td>\n",
       "      <td>731</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>MODERATE</td>\n",
       "      <td>ZFY</td>\n",
       "      <td>chrY:2848029_C/T</td>\n",
       "      <td>Blank</td>\n",
       "      <td>Blank</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2:2</td>\n",
       "      <td>367:359</td>\n",
       "      <td>1:1</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.022260</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1137949 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          d.barcode    DP  VD       AF     HIAF    IMPACT SYMBOL  \\\n",
       "0        4010289633  7281  26 0.003600 0.003300  MODERATE   GNB1   \n",
       "1        4010289633  7281  26 0.003600 0.003300  MODERATE   GNB1   \n",
       "2        4010289633  7281  26 0.003600 0.003300  MODERATE   GNB1   \n",
       "3        4010289633  7281  26 0.003600 0.003300  MODERATE   GNB1   \n",
       "4        4010289633  7282  29 0.004000 0.003600  MODERATE   GNB1   \n",
       "...             ...   ...  ..      ...      ...       ...    ...   \n",
       "1137944  4010290016   731   2 0.002700 0.002800  MODERATE    ZFY   \n",
       "1137945  4010290016   731   2 0.002700 0.002800  MODERATE    ZFY   \n",
       "1137946  4010290016   731   2 0.002700 0.002800  MODERATE    ZFY   \n",
       "1137947  4010290016   731   2 0.002700 0.002800  MODERATE    ZFY   \n",
       "1137948  4010290016   731   2 0.002700 0.002800  MODERATE    ZFY   \n",
       "\n",
       "                     loci sampleTimePt gender    MSID BIAS    REFBIAS VARBIAS  \\\n",
       "0        chr1:1747196_T/C     Baseline   Male  MS2083  2:2  3644:3596   12:14   \n",
       "1        chr1:1747196_T/C     Baseline   Male  MS2083  2:2  3644:3596   12:14   \n",
       "2        chr1:1747196_T/C     Baseline   Male  MS2083  2:2  3644:3596   12:14   \n",
       "3        chr1:1747196_T/C     Baseline   Male  MS2083  2:2  3644:3596   12:14   \n",
       "4        chr1:1747250_T/C     Baseline   Male  MS2083  2:2  3639:3606   15:14   \n",
       "...                   ...          ...    ...     ...  ...        ...     ...   \n",
       "1137944  chrY:2848011_C/T        Blank  Blank     NaN  2:2    371:357     1:1   \n",
       "1137945  chrY:2848029_C/T        Blank  Blank     NaN  2:2    367:359     1:1   \n",
       "1137946  chrY:2848029_C/T        Blank  Blank     NaN  2:2    367:359     1:1   \n",
       "1137947  chrY:2848029_C/T        Blank  Blank     NaN  2:2    367:359     1:1   \n",
       "1137948  chrY:2848029_C/T        Blank  Blank     NaN  2:2    367:359     1:1   \n",
       "\n",
       "             QUAL  ODDRATIO chipOrControl  \n",
       "0       34.000000  1.182210          CHIP  \n",
       "1       34.000000  1.182210          CHIP  \n",
       "2       34.000000  1.182210          CHIP  \n",
       "3       34.000000  1.182210          CHIP  \n",
       "4       32.700000  1.061729          CHIP  \n",
       "...           ...       ...           ...  \n",
       "1137944 31.000000  1.039170           NaN  \n",
       "1137945 37.000000  1.022260           NaN  \n",
       "1137946 37.000000  1.022260           NaN  \n",
       "1137947 37.000000  1.022260           NaN  \n",
       "1137948 37.000000  1.022260           NaN  \n",
       "\n",
       "[1137949 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/chipVariantCalling_run1.tsv\", sep='\\t')\n",
    "df2 = pd.read_csv(\"../data/chipVariantCalling_run2.tsv\", sep='\\t')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = pd.read_csv(\"../data/chipVariantCalling_run1.tsv\", sep='\\t')\n",
    "dataset2 = pd.read_csv(\"../data/chipVariantCalling_run2.tsv\", sep='\\t')\n",
    "\n",
    "unknown1 = dataset1[(dataset1.chipOrControl == \"Unknown\")]\n",
    "unknown2 = dataset2[(dataset2.chipOrControl == \"Unknown\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.chipOrControl != \"Blank\") & (df.chipOrControl != \"Unknown\")]\n",
    "df = df.dropna(subset=['chipOrControl'])\n",
    "df.drop(['MSID', 'd.barcode'], axis=1, inplace=True)\n",
    "# df.drop(['sampleTimePt'], axis = 1, inplace=True)\n",
    "\n",
    "df2 = df2[(df2.chipOrControl != \"Blank\") & (df2.chipOrControl != \"Unknown\")]\n",
    "df2 = df2.dropna(subset=['chipOrControl'])\n",
    "df2.drop(['MSID', 'd.barcode'], axis=1, inplace=True)\n",
    "# df2.drop(['sampleTimePt'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown1 = unknown1[(unknown1.chipOrControl != \"Blank\") & (unknown1.chipOrControl != \"Unknown\")]\n",
    "unknown1 = unknown1.dropna(subset=['chipOrControl'])\n",
    "unknown1.drop(['MSID', 'd.barcode'], axis=1, inplace=True)\n",
    "# unknown1.drop(['sampleTimePt'], axis = 1, inplace=True)\n",
    "\n",
    "unknown2 = unknown2[(unknown2.chipOrControl != \"Blank\") & (unknown2.chipOrControl != \"Unknown\")]\n",
    "unknown2 = unknown2.dropna(subset=['chipOrControl'])\n",
    "unknown2.drop(['MSID', 'd.barcode'], axis=1, inplace=True)\n",
    "# unknown2.drop(['sampleTimePt'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store names of all genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = df.SYMBOL.unique()\n",
    "genes2 = df2.SYMBOL.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DP</th>\n",
       "      <th>VD</th>\n",
       "      <th>AF</th>\n",
       "      <th>HIAF</th>\n",
       "      <th>IMPACT</th>\n",
       "      <th>SYMBOL</th>\n",
       "      <th>loci</th>\n",
       "      <th>sampleTimePt</th>\n",
       "      <th>gender</th>\n",
       "      <th>BIAS</th>\n",
       "      <th>REFBIAS</th>\n",
       "      <th>VARBIAS</th>\n",
       "      <th>QUAL</th>\n",
       "      <th>ODDRATIO</th>\n",
       "      <th>chipOrControl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7281</td>\n",
       "      <td>26</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>MODERATE</td>\n",
       "      <td>GNB1</td>\n",
       "      <td>chr1:1747196_T/C</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>Male</td>\n",
       "      <td>2:2</td>\n",
       "      <td>3644:3596</td>\n",
       "      <td>12:14</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.182210</td>\n",
       "      <td>CHIP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7281</td>\n",
       "      <td>26</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>MODERATE</td>\n",
       "      <td>GNB1</td>\n",
       "      <td>chr1:1747196_T/C</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>Male</td>\n",
       "      <td>2:2</td>\n",
       "      <td>3644:3596</td>\n",
       "      <td>12:14</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.182210</td>\n",
       "      <td>CHIP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7281</td>\n",
       "      <td>26</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>MODERATE</td>\n",
       "      <td>GNB1</td>\n",
       "      <td>chr1:1747196_T/C</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>Male</td>\n",
       "      <td>2:2</td>\n",
       "      <td>3644:3596</td>\n",
       "      <td>12:14</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.182210</td>\n",
       "      <td>CHIP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     DP  VD       AF     HIAF    IMPACT SYMBOL              loci sampleTimePt  \\\n",
       "0  7281  26 0.003600 0.003300  MODERATE   GNB1  chr1:1747196_T/C     Baseline   \n",
       "1  7281  26 0.003600 0.003300  MODERATE   GNB1  chr1:1747196_T/C     Baseline   \n",
       "2  7281  26 0.003600 0.003300  MODERATE   GNB1  chr1:1747196_T/C     Baseline   \n",
       "\n",
       "  gender BIAS    REFBIAS VARBIAS      QUAL  ODDRATIO chipOrControl  \n",
       "0   Male  2:2  3644:3596   12:14 34.000000  1.182210          CHIP  \n",
       "1   Male  2:2  3644:3596   12:14 34.000000  1.182210          CHIP  \n",
       "2   Male  2:2  3644:3596   12:14 34.000000  1.182210          CHIP  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate `loci` into three separate columns: `chromosome` | `chromosome_location` | `nucleotide`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromosome = []\n",
    "chromosome_location = []\n",
    "nucleotide = []\n",
    "\n",
    "for location_string in df.loci.array:\n",
    "    separated = re.split(r\"[:_]+\", location_string)\n",
    "    chromosome.append(separated[0])\n",
    "    chromosome_location.append(separated[1])\n",
    "    nucleotide.append(separated[2])\n",
    "\n",
    "df['chromosome'] = pd.Series(chromosome).values\n",
    "df['chromosome_loc'] = pd.Series(chromosome_location).values\n",
    "df['nucleotide'] = pd.Series(nucleotide).values\n",
    "df.drop(['loci'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromosome = []\n",
    "chromosome_location = []\n",
    "nucleotide = []\n",
    "\n",
    "for location_string in df2.loci.array:\n",
    "    separated = re.split(r\"[:_]+\", location_string)\n",
    "    chromosome.append(separated[0])\n",
    "    chromosome_location.append(separated[1])\n",
    "    nucleotide.append(separated[2])\n",
    "    \n",
    "df2['chromosome'] = pd.Series(chromosome).values\n",
    "df2['chromosome_loc'] = pd.Series(chromosome_location).values\n",
    "df2['nucleotide'] = pd.Series(nucleotide).values\n",
    "df2.drop(['loci'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns `BIAS`, `REFBIAS` and `VARBIAS` are strings. Change to floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_to_int(string):\n",
    "    a, b = string.split(\":\")\n",
    "    if int(b) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return int(a) / int(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bias = []\n",
    "refbias = []\n",
    "varbias = []\n",
    "\n",
    "# for ratio in df.BIAS.array:\n",
    "#     bias.append(ratio_to_int(ratio)) \n",
    "\n",
    "for ratio in df.REFBIAS.array:\n",
    "    refbias.append(ratio_to_int(ratio)) \n",
    "\n",
    "for ratio in df.VARBIAS.array:\n",
    "    varbias.append(ratio_to_int(ratio)) \n",
    "    \n",
    "# bias = pd.Series(bias)\n",
    "refbias = pd.Series(refbias)\n",
    "varbias = pd.Series(varbias)\n",
    "\n",
    "# df['BIAS'] = bias.values\n",
    "df['REFBIAS'] = refbias.values\n",
    "df['VARBIAS'] = varbias.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bias = []\n",
    "refbias = []\n",
    "varbias = []\n",
    "\n",
    "# for ratio in df2.BIAS.array:\n",
    "#     bias.append(ratio_to_int(ratio)) \n",
    "\n",
    "for ratio in df2.REFBIAS.array:\n",
    "    refbias.append(ratio_to_int(ratio)) \n",
    "\n",
    "for ratio in df2.VARBIAS.array:\n",
    "    varbias.append(ratio_to_int(ratio)) \n",
    "    \n",
    "# bias = pd.Series(bias)\n",
    "refbias = pd.Series(refbias)\n",
    "varbias = pd.Series(varbias)\n",
    "\n",
    "# df2['BIAS'] = bias.values\n",
    "df2['REFBIAS'] = refbias.values\n",
    "df2['VARBIAS'] = varbias.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Nick's code. I believe it changes data types to numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "objs = {}\n",
    "lst = []\n",
    "for i in df.columns:\n",
    "    if df.dtypes[i] == object:\n",
    "        if len(df[f\"{i}\"].unique()) <= 100:\n",
    "            objs[i] = len(df[f\"{i}\"].unique())\n",
    "            lst.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "objs = {}\n",
    "lst = []\n",
    "for i in df2.columns:\n",
    "    if df2.dtypes[i] == object:\n",
    "        if len(df2[f\"{i}\"].unique()) <= 100:\n",
    "            objs[i] = len(df2[f\"{i}\"].unique())\n",
    "            lst.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in lst:\n",
    "    k = i\n",
    "    dict = {}\n",
    "    df_new = df\n",
    "    for ix, i in zip(range(len(df_new[i].unique())), df_new[i].unique() ):\n",
    "        dict[i] = ix\n",
    "    df = df.replace({f\"{k}\": dict})\n",
    "    df[f\"{k}\"] = df[f\"{k}\"].astype(str).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in lst:\n",
    "    k = i\n",
    "    dict = {}\n",
    "    df2_new = df2\n",
    "    for ix, i in zip(range(len(df2_new[i].unique())), df2_new[i].unique() ):\n",
    "        dict[i] = ix\n",
    "    df2 = df2.replace({f\"{k}\": dict})\n",
    "    df2[f\"{k}\"] = df2[f\"{k}\"].astype(str).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCI not required in final model\n",
    "df.drop(['chromosome_loc'], axis=1, inplace=True)\n",
    "df2.drop(['chromosome_loc'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCI not required in final model\n",
    "df.drop(['chromosome', 'nucleotide'], axis=1, inplace=True)\n",
    "df2.drop(['chromosome', 'nucleotide'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DP</th>\n",
       "      <th>VD</th>\n",
       "      <th>AF</th>\n",
       "      <th>HIAF</th>\n",
       "      <th>IMPACT</th>\n",
       "      <th>SYMBOL</th>\n",
       "      <th>sampleTimePt</th>\n",
       "      <th>gender</th>\n",
       "      <th>BIAS</th>\n",
       "      <th>REFBIAS</th>\n",
       "      <th>VARBIAS</th>\n",
       "      <th>QUAL</th>\n",
       "      <th>ODDRATIO</th>\n",
       "      <th>chipOrControl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7281</td>\n",
       "      <td>26</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.013348</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.182210</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7282</td>\n",
       "      <td>29</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.009151</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>32.700000</td>\n",
       "      <td>1.061729</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7282</td>\n",
       "      <td>24</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.005268</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.900000</td>\n",
       "      <td>1.005270</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>178</td>\n",
       "      <td>2</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1773</td>\n",
       "      <td>6</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.017162</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.017150</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536717</th>\n",
       "      <td>711</td>\n",
       "      <td>4</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.008523</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.008510</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536725</th>\n",
       "      <td>711</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.008499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.008490</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536733</th>\n",
       "      <td>711</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.005666</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.005660</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536734</th>\n",
       "      <td>711</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.008499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.008490</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536741</th>\n",
       "      <td>711</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.008499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.008490</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111514 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DP  VD       AF     HIAF   IMPACT    SYMBOL  sampleTimePt   gender  \\\n",
       "0       7281  26 0.003600 0.003300 0.000000  0.000000      0.000000 0.000000   \n",
       "4       7282  29 0.004000 0.003600 0.000000  0.000000      0.000000 0.000000   \n",
       "8       7282  24 0.003300 0.003300 0.000000  0.000000      0.000000 0.000000   \n",
       "12       178   2 0.011200 0.012000 0.000000  1.000000      0.000000 0.000000   \n",
       "13      1773   6 0.003400 0.003500 0.000000  1.000000      0.000000 0.000000   \n",
       "...      ...  ..      ...      ...      ...       ...           ...      ...   \n",
       "536717   711   4 0.005600 0.005700 0.000000 28.000000      1.000000 1.000000   \n",
       "536725   711   2 0.002800 0.002800 0.000000 28.000000      1.000000 1.000000   \n",
       "536733   711   2 0.002800 0.002900 1.000000 28.000000      1.000000 1.000000   \n",
       "536734   711   2 0.002800 0.002900 0.000000 28.000000      1.000000 1.000000   \n",
       "536741   711   2 0.002800 0.002800 0.000000 28.000000      1.000000 1.000000   \n",
       "\n",
       "           BIAS  REFBIAS  VARBIAS      QUAL  ODDRATIO  chipOrControl  \n",
       "0      0.000000 1.013348 0.857143 34.000000  1.182210       0.000000  \n",
       "4      0.000000 1.009151 1.071429 32.700000  1.061729       0.000000  \n",
       "8      0.000000 1.005268 1.000000 34.900000  1.005270       0.000000  \n",
       "12     0.000000 1.000000 1.000000 37.000000  1.000000       0.000000  \n",
       "13     0.000000 1.017162 1.000000 37.000000  1.017150       0.000000  \n",
       "...         ...      ...      ...       ...       ...            ...  \n",
       "536717 0.000000 1.008523 1.000000 37.000000  1.008510       1.000000  \n",
       "536725 0.000000 1.008499 1.000000 31.000000  1.008490       1.000000  \n",
       "536733 0.000000 1.005666 1.000000 37.000000  1.005660       1.000000  \n",
       "536734 0.000000 1.008499 1.000000 37.000000  1.008490       1.000000  \n",
       "536741 0.000000 1.008499 1.000000 25.000000  1.008490       1.000000  \n",
       "\n",
       "[111514 rows x 14 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df2.drop_duplicates(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONE HOT ENCODE \"SYMBOL\" with pd.get_dummies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.concat([df,pd.get_dummies(df['SYMBOL'], prefix='GENE')],axis=1)\n",
    "df_model2 = pd.concat([df2,pd.get_dummies(df2['SYMBOL'], prefix='GENE')],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.drop(['SYMBOL'],axis=1, inplace=True)\n",
    "df_model2.drop(['SYMBOL'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_genes = df_model.columns[15:]\n",
    "dummy_genes2 = df_model2.columns[15:]\n",
    "\n",
    "d = {}\n",
    "d2 = {}\n",
    "\n",
    "for i in range(len(dummy_genes)):\n",
    "    d[dummy_genes[i]] = genes[i]\n",
    "\n",
    "for i in range(len(dummy_genes2)):\n",
    "    d2[dummy_genes2[i]] = genes2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_model.rename(d, axis=1)  # Renaming columns\n",
    "df_model2 = df_model2.rename(d2, axis=1)  # Renaming columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retain top 5 genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove other genes from dataframe\n",
    "df_model = df_model[['DP', 'VD', 'AF', 'HIAF', 'IMPACT', 'sampleTimePt', 'gender', 'BIAS',\n",
    "       'REFBIAS', 'VARBIAS', 'QUAL', 'ODDRATIO', 'chipOrControl', 'DNMT3A', 'TET2', 'TP53', 'ASXL1', 'BCOR']]\n",
    "\n",
    "df_model2 = df_model2[['DP', 'VD', 'AF', 'HIAF', 'IMPACT', 'sampleTimePt', 'gender', 'BIAS',\n",
    "       'REFBIAS', 'VARBIAS', 'QUAL', 'ODDRATIO', 'chipOrControl', 'DNMT3A', 'TET2', 'TP53', 'ASXL1', 'BCOR']]\n",
    "\n",
    "\n",
    "# Create separate dataframe\n",
    "encoder = df_model[['DNMT3A', 'TET2', 'TP53', 'ASXL1', 'BCOR']]\n",
    "encoder2 = df_model2[['DNMT3A', 'TET2', 'TP53', 'ASXL1', 'BCOR']]\n",
    "\n",
    "# Sum of one hot encode. Value = 1 if exists, 0 otherwise\n",
    "p = encoder[list(encoder)].sum(axis=1).array\n",
    "p2 = encoder2[list(encoder2)].sum(axis=1).array\n",
    "\n",
    "# Flip values\n",
    "for i in range(len(p)):\n",
    "    if p[i] == 0:\n",
    "        p[i] = 1\n",
    "    else:\n",
    "        p[i] = 0\n",
    "\n",
    "# Flip values\n",
    "for i in range(len(p2)):\n",
    "    if p2[i] == 0:\n",
    "        p2[i] = 1\n",
    "    else:\n",
    "        p2[i] = 0\n",
    "        \n",
    "# Add to df\n",
    "df_model[\"other\"] = p\n",
    "df_model2[\"other\"] = p2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot encode `BIAS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bias_str = [\"twotwo\", \"onezero\", \"zerotwo\", \"onetwo\", \"twozero\", \"oneone\", \"zerozero\", \"twoone\"]\n",
    "# bias_str2 = [\"twotwo\", \"twozero\", \"onezero\", \"zerotwo\", \"oneone\", \"twoone\", \"onetwo\", \"zerozero\"]\n",
    "\n",
    "# df_model = pd.concat([df_model, pd.get_dummies(df_model['BIAS'])],axis=1)\n",
    "# df_model2 = pd.concat([df_model2, pd.get_dummies(df_model2['BIAS'])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy_bias = pd.concat([df,pd.get_dummies(df['BIAS'])],axis=1).columns[14:]\n",
    "\n",
    "\n",
    "# b = {}\n",
    "# b2 = {}\n",
    "\n",
    "# for i in range(len(dummy_bias)):\n",
    "#     b[dummy_bias[i]] = bias_str[i]\n",
    "\n",
    "# for i in range(len(dummy_bias)):\n",
    "#     b2[dummy_bias[i]] = bias_str2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_model.drop(['BIAS'],axis=1, inplace=True)\n",
    "# df_model2.drop(['BIAS'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_model = df_model.rename(b, axis=1)  # Renaming columns\n",
    "# df_model2 = df_model2.rename(b2, axis=1)  # Renaming columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create closed datasets\n",
    "- Remove rows in relation to outliers\n",
    "- Compare values at the 98th percentile\n",
    "- Reject QUAL values less than 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0372048\n",
      "1.0690527335697206\n",
      "1.5\n",
      "2.0983787999999985\n",
      "54.97636363636279\n",
      "2.0\n",
      "\n",
      "14.7623265426631\n",
      "1.1422222626258425\n",
      "11.289523809523661\n",
      "18.541455123750726\n",
      "12.266153846148743\n",
      "14.566349206349095\n"
     ]
    }
   ],
   "source": [
    "print(df_model.ODDRATIO.quantile(0.98))\n",
    "print(df_model.REFBIAS.quantile(0.98))\n",
    "print(df_model.VARBIAS.quantile(0.98))\n",
    "\n",
    "print(df_model.ODDRATIO.quantile(0.99))\n",
    "print(df_model.REFBIAS.quantile(0.99))\n",
    "print(df_model.VARBIAS.quantile(0.99))\n",
    "\n",
    "print()\n",
    "\n",
    "print(df_model2.ODDRATIO.quantile(0.98))\n",
    "print(df_model2.REFBIAS.quantile(0.98))\n",
    "print(df_model2.VARBIAS.quantile(0.98))\n",
    "\n",
    "print(df_model2.ODDRATIO.quantile(0.99))\n",
    "print(df_model2.REFBIAS.quantile(0.99))\n",
    "print(df_model2.VARBIAS.quantile(0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above display the second dataset contains more noise IF ratios are examined as quantitative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_odd = df_model[df_model['ODDRATIO'] < 3]\n",
    "low_odd_refbias = low_odd[low_odd['REFBIAS'] < 1.3]\n",
    "low_odd_refbias_varbias = low_odd_refbias[low_odd_refbias['VARBIAS'] <= 2]\n",
    "df_model_removed = low_odd_refbias_varbias[low_odd_refbias_varbias['QUAL'] >= 30]\n",
    "# df_model_removed = df_model_removed[df_model_removed['DP'] >= ]\n",
    "\n",
    "low_odd = df_model2[df_model2['ODDRATIO'] < 3]\n",
    "low_odd_refbias = low_odd[low_odd['REFBIAS'] < 1.3]\n",
    "low_odd_refbias_varbias = low_odd_refbias[low_odd_refbias['VARBIAS'] <= 2]\n",
    "df_model_removed2 = low_odd_refbias_varbias[low_odd_refbias_varbias['QUAL'] >= 30]\n",
    "# df_model_removed = df_model_removed[df_model_removed['DP'] >= 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop AF due to high correlation with HIAF. Drop duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.drop('AF', axis = 1, inplace = True)\n",
    "df_model2.drop('AF', axis = 1, inplace = True)\n",
    "df_model_removed.drop('AF', axis = 1, inplace = True)\n",
    "df_model_removed2.drop('AF', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.drop_duplicates(inplace=True)\n",
    "df_model2.drop_duplicates(inplace=True)\n",
    "df_model_removed.drop_duplicates(inplace=True)\n",
    "df_model_removed2.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DP</th>\n",
       "      <th>VD</th>\n",
       "      <th>HIAF</th>\n",
       "      <th>IMPACT</th>\n",
       "      <th>sampleTimePt</th>\n",
       "      <th>gender</th>\n",
       "      <th>BIAS</th>\n",
       "      <th>REFBIAS</th>\n",
       "      <th>VARBIAS</th>\n",
       "      <th>QUAL</th>\n",
       "      <th>ODDRATIO</th>\n",
       "      <th>chipOrControl</th>\n",
       "      <th>DNMT3A</th>\n",
       "      <th>TET2</th>\n",
       "      <th>TP53</th>\n",
       "      <th>ASXL1</th>\n",
       "      <th>BCOR</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>102604.000000</td>\n",
       "      <td>102604.000000</td>\n",
       "      <td>102604.000000</td>\n",
       "      <td>102604.000000</td>\n",
       "      <td>102604.000000</td>\n",
       "      <td>102604.000000</td>\n",
       "      <td>102604.000000</td>\n",
       "      <td>102604.000000</td>\n",
       "      <td>102604.000000</td>\n",
       "      <td>102604.000000</td>\n",
       "      <td>102604.000000</td>\n",
       "      <td>102604.000000</td>\n",
       "      <td>102604.000000</td>\n",
       "      <td>102604.000000</td>\n",
       "      <td>102604.000000</td>\n",
       "      <td>102604.000000</td>\n",
       "      <td>102604.000000</td>\n",
       "      <td>102604.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5867.196308</td>\n",
       "      <td>109.637655</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.053702</td>\n",
       "      <td>0.521880</td>\n",
       "      <td>0.481979</td>\n",
       "      <td>0.069432</td>\n",
       "      <td>0.986892</td>\n",
       "      <td>0.978736</td>\n",
       "      <td>35.722231</td>\n",
       "      <td>1.019106</td>\n",
       "      <td>0.446873</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>0.018995</td>\n",
       "      <td>0.037767</td>\n",
       "      <td>0.006549</td>\n",
       "      <td>0.020155</td>\n",
       "      <td>0.914769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13124.963334</td>\n",
       "      <td>2004.422850</td>\n",
       "      <td>0.065289</td>\n",
       "      <td>0.225429</td>\n",
       "      <td>0.499523</td>\n",
       "      <td>0.499678</td>\n",
       "      <td>0.474893</td>\n",
       "      <td>0.186432</td>\n",
       "      <td>0.213639</td>\n",
       "      <td>1.877877</td>\n",
       "      <td>0.228002</td>\n",
       "      <td>0.497172</td>\n",
       "      <td>0.041964</td>\n",
       "      <td>0.136509</td>\n",
       "      <td>0.190632</td>\n",
       "      <td>0.080664</td>\n",
       "      <td>0.140532</td>\n",
       "      <td>0.279226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>556.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.012594</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.013130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1270.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.019914</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.022420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5412.500000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.028400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.037590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>455487.000000</td>\n",
       "      <td>146473.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.295203</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>2.977520</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DP            VD          HIAF        IMPACT  sampleTimePt  \\\n",
       "count 102604.000000 102604.000000 102604.000000 102604.000000 102604.000000   \n",
       "mean    5867.196308    109.637655      0.010700      0.053702      0.521880   \n",
       "std    13124.963334   2004.422850      0.065289      0.225429      0.499523   \n",
       "min        2.000000      2.000000      0.001900      0.000000      0.000000   \n",
       "25%      556.000000      2.000000      0.002800      0.000000      0.000000   \n",
       "50%     1270.000000      4.000000      0.003500      0.000000      1.000000   \n",
       "75%     5412.500000     17.000000      0.005300      0.000000      1.000000   \n",
       "max   455487.000000 146473.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "             gender          BIAS       REFBIAS       VARBIAS          QUAL  \\\n",
       "count 102604.000000 102604.000000 102604.000000 102604.000000 102604.000000   \n",
       "mean       0.481979      0.069432      0.986892      0.978736     35.722231   \n",
       "std        0.499678      0.474893      0.186432      0.213639      1.877877   \n",
       "min        0.000000      0.000000      0.000000      0.000000     30.000000   \n",
       "25%        0.000000      0.000000      1.012594      1.000000     35.000000   \n",
       "50%        0.000000      0.000000      1.019914      1.000000     37.000000   \n",
       "75%        1.000000      0.000000      1.028400      1.000000     37.000000   \n",
       "max        1.000000      6.000000      1.295203      2.000000     37.000000   \n",
       "\n",
       "           ODDRATIO  chipOrControl        DNMT3A          TET2          TP53  \\\n",
       "count 102604.000000  102604.000000 102604.000000 102604.000000 102604.000000   \n",
       "mean       1.019106       0.446873      0.001764      0.018995      0.037767   \n",
       "std        0.228002       0.497172      0.041964      0.136509      0.190632   \n",
       "min        0.000000       0.000000      0.000000      0.000000      0.000000   \n",
       "25%        1.013130       0.000000      0.000000      0.000000      0.000000   \n",
       "50%        1.022420       0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.037590       1.000000      0.000000      0.000000      0.000000   \n",
       "max        2.977520       1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "              ASXL1          BCOR         other  \n",
       "count 102604.000000 102604.000000 102604.000000  \n",
       "mean       0.006549      0.020155      0.914769  \n",
       "std        0.080664      0.140532      0.279226  \n",
       "min        0.000000      0.000000      0.000000  \n",
       "25%        0.000000      0.000000      1.000000  \n",
       "50%        0.000000      0.000000      1.000000  \n",
       "75%        0.000000      0.000000      1.000000  \n",
       "max        1.000000      1.000000      1.000000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_removed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalise Data\n",
    "Create new dataframes to be trained/tested within models by normalising quantitative variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DP</th>\n",
       "      <th>VD</th>\n",
       "      <th>HIAF</th>\n",
       "      <th>IMPACT</th>\n",
       "      <th>sampleTimePt</th>\n",
       "      <th>gender</th>\n",
       "      <th>BIAS</th>\n",
       "      <th>REFBIAS</th>\n",
       "      <th>VARBIAS</th>\n",
       "      <th>QUAL</th>\n",
       "      <th>ODDRATIO</th>\n",
       "      <th>chipOrControl</th>\n",
       "      <th>DNMT3A</th>\n",
       "      <th>TET2</th>\n",
       "      <th>TP53</th>\n",
       "      <th>ASXL1</th>\n",
       "      <th>BCOR</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2036</td>\n",
       "      <td>6</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.957230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.044670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2036</td>\n",
       "      <td>7</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.988224</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>35.300000</td>\n",
       "      <td>1.317450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2040</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.988166</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>31.800000</td>\n",
       "      <td>1.481960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2041</td>\n",
       "      <td>6</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.983415</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.700000</td>\n",
       "      <td>1.016860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2037</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.894942</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>1.342210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692971</th>\n",
       "      <td>2130</td>\n",
       "      <td>9</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.915913</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>34.100000</td>\n",
       "      <td>1.364554</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692986</th>\n",
       "      <td>2076</td>\n",
       "      <td>6</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.824007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692993</th>\n",
       "      <td>2069</td>\n",
       "      <td>7</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.747064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693021</th>\n",
       "      <td>4805</td>\n",
       "      <td>13</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000839</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.167610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693035</th>\n",
       "      <td>4788</td>\n",
       "      <td>14</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.998316</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.001683</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100430 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DP  VD     HIAF   IMPACT  sampleTimePt   gender     BIAS  REFBIAS  \\\n",
       "0       2036   6 0.004400 0.000000      0.000000 0.000000 0.000000 0.957230   \n",
       "5       2036   7 0.003500 1.000000      0.000000 0.000000 0.000000 0.988224   \n",
       "9       2040   5 0.002100 1.000000      0.000000 0.000000 0.000000 0.988166   \n",
       "13      2041   6 0.002500 1.000000      0.000000 0.000000 0.000000 0.983415   \n",
       "17      2037   5 0.002800 1.000000      0.000000 0.000000 0.000000 0.894942   \n",
       "...      ...  ..      ...      ...           ...      ...      ...      ...   \n",
       "692971  2130   9 0.003800 1.000000      1.000000 1.000000 0.000000 0.915913   \n",
       "692986  2076   6 0.002900 1.000000      1.000000 1.000000 1.000000 0.824007   \n",
       "692993  2069   7 0.003500 1.000000      1.000000 1.000000 1.000000 0.747064   \n",
       "693021  4805  13 0.002700 1.000000      1.000000 1.000000 0.000000 1.000839   \n",
       "693035  4788  14 0.003000 1.000000      1.000000 1.000000 0.000000 0.998316   \n",
       "\n",
       "        VARBIAS      QUAL  ODDRATIO  chipOrControl  DNMT3A  TET2  TP53  ASXL1  \\\n",
       "0      1.000000 35.000000  1.044670       0.000000       0     0     0      0   \n",
       "5      0.750000 35.300000  1.317450       0.000000       0     0     0      0   \n",
       "9      0.666667 31.800000  1.481960       0.000000       0     0     0      0   \n",
       "13     1.000000 32.700000  1.016860       0.000000       0     0     0      0   \n",
       "17     0.666667 32.200000  1.342210       0.000000       0     0     0      0   \n",
       "...         ...       ...       ...            ...     ...   ...   ...    ...   \n",
       "692971 1.250000 34.100000  1.364554       1.000000       0     0     0      0   \n",
       "692986 0.000000 35.400000  0.000000       1.000000       0     0     0      0   \n",
       "692993 0.000000 35.900000  0.000000       1.000000       0     0     0      0   \n",
       "693021 0.857143 35.000000  1.167610       1.000000       0     0     0      0   \n",
       "693035 1.000000 37.000000  1.001683       1.000000       0     0     0      0   \n",
       "\n",
       "        BCOR  other  \n",
       "0          0      1  \n",
       "5          0      1  \n",
       "9          0      1  \n",
       "13         0      1  \n",
       "17         0      1  \n",
       "...      ...    ...  \n",
       "692971     1      0  \n",
       "692986     1      0  \n",
       "692993     1      0  \n",
       "693021     1      0  \n",
       "693035     1      0  \n",
       "\n",
       "[100430 rows x 18 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_removed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(dataframe):\n",
    "    norms = dataframe[['DP', 'VD', 'HIAF', 'REFBIAS', 'VARBIAS', 'QUAL', 'ODDRATIO']]\n",
    "    norms = (norms-norms.mean())/norms.std()\n",
    "#     norms = pd.concat([norms, dataframe[['IMPACT', 'sampleTimePt', 'gender', 'chipOrControl', 'DNMT3A', 'TET2', 'TP53', 'ASXL1',\n",
    "#                                            'BCOR', 'other', 'twotwo', 'onezero', 'zerotwo', 'onetwo', 'twozero',\n",
    "#                                          'oneone', 'zerozero', 'twoone'] ]],axis=1)\n",
    "    \n",
    "    norms = pd.concat([norms, dataframe[['IMPACT', 'sampleTimePt', 'gender', 'chipOrControl', 'DNMT3A', 'TET2', 'TP53', 'ASXL1',\n",
    "                                       'BCOR', 'other'] ]],axis=1)\n",
    "    \n",
    "    return norms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df_model = normalise(df_model)\n",
    "norm_df_model2 = normalise(df_model2)\n",
    "norm_df_model_removed = normalise(df_model_removed)\n",
    "norm_df_model_removed2 = normalise(df_model_removed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DP</th>\n",
       "      <th>VD</th>\n",
       "      <th>HIAF</th>\n",
       "      <th>REFBIAS</th>\n",
       "      <th>VARBIAS</th>\n",
       "      <th>QUAL</th>\n",
       "      <th>ODDRATIO</th>\n",
       "      <th>IMPACT</th>\n",
       "      <th>sampleTimePt</th>\n",
       "      <th>gender</th>\n",
       "      <th>chipOrControl</th>\n",
       "      <th>DNMT3A</th>\n",
       "      <th>TET2</th>\n",
       "      <th>TP53</th>\n",
       "      <th>ASXL1</th>\n",
       "      <th>BCOR</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.111750</td>\n",
       "      <td>-0.039057</td>\n",
       "      <td>-0.111933</td>\n",
       "      <td>-0.040965</td>\n",
       "      <td>-0.058840</td>\n",
       "      <td>-0.478556</td>\n",
       "      <td>-0.010949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.111826</td>\n",
       "      <td>-0.038046</td>\n",
       "      <td>-0.107488</td>\n",
       "      <td>-0.040976</td>\n",
       "      <td>0.036889</td>\n",
       "      <td>-0.970238</td>\n",
       "      <td>-0.013579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.111826</td>\n",
       "      <td>-0.039731</td>\n",
       "      <td>-0.111933</td>\n",
       "      <td>-0.040987</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>-0.138160</td>\n",
       "      <td>-0.014812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.424884</td>\n",
       "      <td>-0.047143</td>\n",
       "      <td>0.016982</td>\n",
       "      <td>-0.041001</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.656097</td>\n",
       "      <td>-0.014927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.304381</td>\n",
       "      <td>-0.045796</td>\n",
       "      <td>-0.108970</td>\n",
       "      <td>-0.040954</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.656097</td>\n",
       "      <td>-0.014552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536717</th>\n",
       "      <td>-0.384615</td>\n",
       "      <td>-0.046469</td>\n",
       "      <td>-0.076370</td>\n",
       "      <td>-0.040978</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.656097</td>\n",
       "      <td>-0.014741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536725</th>\n",
       "      <td>-0.384615</td>\n",
       "      <td>-0.047143</td>\n",
       "      <td>-0.119342</td>\n",
       "      <td>-0.040978</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>-1.613208</td>\n",
       "      <td>-0.014741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536733</th>\n",
       "      <td>-0.384615</td>\n",
       "      <td>-0.047143</td>\n",
       "      <td>-0.117860</td>\n",
       "      <td>-0.040986</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.656097</td>\n",
       "      <td>-0.014803</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536734</th>\n",
       "      <td>-0.384615</td>\n",
       "      <td>-0.047143</td>\n",
       "      <td>-0.117860</td>\n",
       "      <td>-0.040978</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.656097</td>\n",
       "      <td>-0.014741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536741</th>\n",
       "      <td>-0.384615</td>\n",
       "      <td>-0.047143</td>\n",
       "      <td>-0.119342</td>\n",
       "      <td>-0.040978</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>-3.882513</td>\n",
       "      <td>-0.014741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110193 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              DP        VD      HIAF   REFBIAS   VARBIAS      QUAL  ODDRATIO  \\\n",
       "0       0.111750 -0.039057 -0.111933 -0.040965 -0.058840 -0.478556 -0.010949   \n",
       "4       0.111826 -0.038046 -0.107488 -0.040976  0.036889 -0.970238 -0.013579   \n",
       "8       0.111826 -0.039731 -0.111933 -0.040987  0.004980 -0.138160 -0.014812   \n",
       "12     -0.424884 -0.047143  0.016982 -0.041001  0.004980  0.656097 -0.014927   \n",
       "13     -0.304381 -0.045796 -0.108970 -0.040954  0.004980  0.656097 -0.014552   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "536717 -0.384615 -0.046469 -0.076370 -0.040978  0.004980  0.656097 -0.014741   \n",
       "536725 -0.384615 -0.047143 -0.119342 -0.040978  0.004980 -1.613208 -0.014741   \n",
       "536733 -0.384615 -0.047143 -0.117860 -0.040986  0.004980  0.656097 -0.014803   \n",
       "536734 -0.384615 -0.047143 -0.117860 -0.040978  0.004980  0.656097 -0.014741   \n",
       "536741 -0.384615 -0.047143 -0.119342 -0.040978  0.004980 -3.882513 -0.014741   \n",
       "\n",
       "         IMPACT  sampleTimePt   gender  chipOrControl  DNMT3A  TET2  TP53  \\\n",
       "0      0.000000      0.000000 0.000000       0.000000       0     0     0   \n",
       "4      0.000000      0.000000 0.000000       0.000000       0     0     0   \n",
       "8      0.000000      0.000000 0.000000       0.000000       0     0     0   \n",
       "12     0.000000      0.000000 0.000000       0.000000       0     0     0   \n",
       "13     0.000000      0.000000 0.000000       0.000000       0     0     0   \n",
       "...         ...           ...      ...            ...     ...   ...   ...   \n",
       "536717 0.000000      1.000000 1.000000       1.000000       0     0     0   \n",
       "536725 0.000000      1.000000 1.000000       1.000000       0     0     0   \n",
       "536733 1.000000      1.000000 1.000000       1.000000       0     0     0   \n",
       "536734 0.000000      1.000000 1.000000       1.000000       0     0     0   \n",
       "536741 0.000000      1.000000 1.000000       1.000000       0     0     0   \n",
       "\n",
       "        ASXL1  BCOR  other  \n",
       "0           0     0      1  \n",
       "4           0     0      1  \n",
       "8           0     0      1  \n",
       "12          0     0      1  \n",
       "13          0     0      1  \n",
       "...       ...   ...    ...  \n",
       "536717      0     1      0  \n",
       "536725      0     1      0  \n",
       "536733      0     1      0  \n",
       "536734      0     1      0  \n",
       "536741      0     1      0  \n",
       "\n",
       "[110193 rows x 17 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_df_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd May Workings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DP', 'VD', 'HIAF', 'IMPACT', 'sampleTimePt', 'gender', 'BIAS',\n",
       "       'REFBIAS', 'VARBIAS', 'QUAL', 'ODDRATIO', 'chipOrControl', 'DNMT3A',\n",
       "       'TET2', 'TP53', 'ASXL1', 'BCOR', 'other'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.drop(['DNMT3A', 'TET2', 'TP53', 'ASXL1', 'BCOR', 'other'], axis=1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.drop(['QUAL', 'BIAS', 'VARBIAS', 'IMPACT'], axis=1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_other = df_model[df_model['DP'] > 10]\n",
    "df_other = df_other[df_other['ODDRATIO'] < 1.5]\n",
    "df_other = df_other[df_other['REFBIAS'] < 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_other = df_other[df_other['HIAF'] < 0.027]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(dataframe):\n",
    "    norms = dataframe[['DP', 'VD', 'HIAF', 'REFBIAS', 'ODDRATIO']]\n",
    "    norms = (norms-norms.mean())/norms.std()\n",
    "#     norms = pd.concat([norms, dataframe[['IMPACT', 'sampleTimePt', 'gender', 'chipOrControl', 'DNMT3A', 'TET2', 'TP53', 'ASXL1',\n",
    "#                                            'BCOR', 'other', 'twotwo', 'onezero', 'zerotwo', 'onetwo', 'twozero',\n",
    "#                                          'oneone', 'zerozero', 'twoone'] ]],axis=1)\n",
    "    \n",
    "    norms = pd.concat([norms, dataframe[['sampleTimePt', 'gender', 'chipOrControl'] ]],axis=1)\n",
    "    \n",
    "    return norms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_other1 = normalise(df_other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_model.drop('chipOrControl', axis = 1) \n",
    "y = df_model['chipOrControl'] \n",
    "\n",
    "X_other = df_other.drop('chipOrControl', axis = 1) \n",
    "y_other = df_other['chipOrControl'] \n",
    "\n",
    "X_other1 = df_other1.drop('chipOrControl', axis = 1) \n",
    "y_other1 = df_other1['chipOrControl'] \n",
    "\n",
    "\n",
    "X_2 = df_model2.drop('chipOrControl', axis = 1) \n",
    "y_2 = df_model2['chipOrControl'] \n",
    "\n",
    "norm_X = norm_df_model.drop('chipOrControl', axis = 1) \n",
    "norm_y = norm_df_model['chipOrControl'] \n",
    "\n",
    "norm_X_2 = norm_df_model2.drop('chipOrControl', axis = 1) \n",
    "norm_y_2 = norm_df_model2['chipOrControl']\n",
    "\n",
    "removed_X = df_model_removed.drop('chipOrControl', axis = 1) \n",
    "removed_y = df_model_removed['chipOrControl'] \n",
    "\n",
    "removed_X_2 = df_model_removed2.drop('chipOrControl', axis = 1) \n",
    "removed_y_2 = df_model_removed2['chipOrControl'] \n",
    "\n",
    "norm_removed_X = norm_df_model_removed.drop('chipOrControl', axis = 1) \n",
    "norm_removed_y = norm_df_model_removed['chipOrControl'] \n",
    "\n",
    "norm_removed_X_2 = norm_df_model_removed2.drop('chipOrControl', axis = 1) \n",
    "norm_removed_y_2 = norm_df_model_removed2['chipOrControl'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests\n",
    "Run a random forest classifer, training/testing on individual datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.64\n"
     ]
    }
   ],
   "source": [
    "# Split into training/testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8, random_state=0)\n",
    "\n",
    "# instantatiate the RFC with 100 ensemble members\n",
    "clf = RandomForestClassifier(n_estimators = 100)\n",
    "clf.fit(X_train, y_train)\n",
    "Y_pred = clf.predict(X_test)  \n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, Y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.641\n"
     ]
    }
   ],
   "source": [
    "# Split into training/testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_other, y_other, train_size=.8, random_state=0)\n",
    "\n",
    "# instantatiate the RFC with 100 ensemble members\n",
    "clf = RandomForestClassifier(n_estimators = 100)\n",
    "clf.fit(X_train, y_train)\n",
    "Y_pred = clf.predict(X_test)  \n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, Y_pred),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_2, y_2, train_size=.8, random_state=0)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "Y_pred = clf.predict(X_test)  # calculate the predicted values\n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, Y_pred),3)))\n",
    "\n",
    "run2_pred = clf.predict(X)\n",
    "print('Accuracy out of sample {0}'.format(np.round(accuracy_score(y, run2_pred),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 1 filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(removed_X, removed_y, train_size=.8, random_state=0)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "Y_pred = clf.predict(X_test)  # calculate the predicted values\n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, Y_pred),3)))\n",
    "\n",
    "run2_pred = clf.predict(removed_X_2)\n",
    "print('Accuracy out of sample {0}'.format(np.round(accuracy_score(removed_y_2, run2_pred),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 2 filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(removed_X_2, removed_y_2, train_size=.8, random_state=0)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "Y_pred = clf.predict(X_test)  # calculate the predicted values\n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, Y_pred),3)))\n",
    "\n",
    "run2_pred = clf.predict(removed_X)\n",
    "print('Accuracy out of sample {0}'.format(np.round(accuracy_score(removed_y, run2_pred),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalised Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(norm_X, norm_y, train_size=.8, random_state=0)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "Y_pred = clf.predict(X_test)  # calculate the predicted values\n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, Y_pred),3)))\n",
    "\n",
    "run2_pred = clf.predict(norm_X_2)\n",
    "print('Accuracy out of sample {0}'.format(np.round(accuracy_score(norm_y_2, run2_pred),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalised Datset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(norm_X_2, norm_y_2, train_size=.8, random_state=0)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "Y_pred = clf.predict(X_test)  # calculate the predicted values\n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, Y_pred),3)))\n",
    "\n",
    "run2_pred = clf.predict(norm_X)\n",
    "print('Accuracy out of sample {0}'.format(np.round(accuracy_score(norm_y, run2_pred),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalised Dataset 1 Filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(norm_removed_X, norm_removed_y, train_size=.8, random_state=0)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "Y_pred = clf.predict(X_test)  # calculate the predicted values\n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, Y_pred),3)))\n",
    "\n",
    "run2_pred = clf.predict(norm_removed_X_2)\n",
    "print('Accuracy out of sample {0}'.format(np.round(accuracy_score(norm_removed_y_2, run2_pred),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalised Dataset 2 Filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(norm_removed_X_2, norm_removed_y_2, train_size=.8, random_state=0)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "Y_pred = clf.predict(X_test)  # calculate the predicted values\n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, Y_pred),3)))\n",
    "\n",
    "run2_pred = clf.predict(norm_removed_X)\n",
    "print('Accuracy out of sample {0}'.format(np.round(accuracy_score(norm_removed_y, run2_pred),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_model.drop('chipOrControl', axis = 1) # drop the target variable for the features\n",
    "y = df_model['chipOrControl'] # create a target dataframe\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  5.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'bootstrap': [False], 'criterion': ['gini'],\n",
       "                         'max_depth': ['None', 3, 5], 'max_features': ['auto'],\n",
       "                         'min_samples_leaf': [1, 5, 10],\n",
       "                         'min_samples_split': [2, 40],\n",
       "                         'n_estimators': [100, 200]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "param_grid = {'n_estimators': [100, 200], 'min_samples_split': [2, 40], 'min_samples_leaf': [1, 5, 10], \n",
    "              'max_features': ['auto'], 'max_depth': ['None', 3, 5], 'criterion': ['gini'], 'bootstrap': [False]}\n",
    "\n",
    "random_forest_CV = GridSearchCV(estimator=random_forest, param_grid=param_grid, verbose=2, n_jobs = -1) \n",
    "random_forest_CV.fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': False, 'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 40, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(random_forest_CV.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random_forest_CV.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = random_forest_CV.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.558\n"
     ]
    }
   ],
   "source": [
    "# instantatiate the RFC with 100 ensemble members\n",
    "clf = RandomForestClassifier(max_depth = 5, min_samples_leaf = 5, min_samples_split = 40, n_estimators = 100, criterion ='gini')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run2_pred = clf.predict(X_2)\n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_2, run2_pred),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.668\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8, random_state=0)\n",
    "\n",
    "clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(),\n",
    "    n_estimators=300, learning_rate = 1.5, algorithm= 'SAMME')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.698\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8, random_state=0)\n",
    "\n",
    "clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(),\n",
    "    n_estimators=100, learning_rate = 0.5, algorithm= 'SAMME')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "could not allocate 3670016 bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-4f5e3f930d58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     n_estimators=100, learning_rate = 0.5, algorithm= 'SAMME')\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[1;31m# Fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0miboost\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;31m# Boosting step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             sample_weight, estimator_weight, estimator_error = self._boost(\n\u001b[0m\u001b[0;32m    131\u001b[0m                 \u001b[0miboost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m             return self._boost_discrete(iboost, X, y, sample_weight,\n\u001b[0m\u001b[0;32m    507\u001b[0m                                         random_state)\n\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36m_boost_discrete\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[0my_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    387\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    166\u001b[0m                                                         indices=indices)\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    888\u001b[0m         \"\"\"\n\u001b[0;32m    889\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 890\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    891\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn\\tree\\_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msklearn\\tree\\_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msklearn\\tree\\_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.Tree._add_node\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msklearn\\tree\\_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.Tree._resize_c\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msklearn\\tree\\_utils.pyx\u001b[0m in \u001b[0;36msklearn.tree._utils.safe_realloc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: could not allocate 3670016 bytes"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8, random_state=0)\n",
    "\n",
    "clf = AdaBoostClassifier(\n",
    "    RandomForestClassifier(),\n",
    "    n_estimators=100, learning_rate = 0.5, algorithm= 'SAMME')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.661\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8, random_state=0)\n",
    "\n",
    "clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier())\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:  8.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.001, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "gs_ab = GridSearchCV(AdaBoostClassifier(), param_grid = param_grid, n_jobs = -1, verbose = 3)\n",
    "gs_ab.fit(X, y)\n",
    "print(gs_ab.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting train data for model tuning with cross-validation\n",
    "cv_n_split = 3\n",
    "random_state = 40\n",
    "test_train_split_part = 0.2\n",
    "\n",
    "cv_train = ShuffleSplit(n_splits=cv_n_split, test_size=test_train_split_part, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extra Trees Classifier\n",
    "\n",
    "etr = ExtraTreesClassifier()\n",
    "etr_CV = GridSearchCV(estimator=etr, param_grid={'min_samples_leaf' : [11, 12, 13, 14]}, cv=cv_train, verbose=3)\n",
    "etr_CV.fit(X, y)\n",
    "print(etr_CV.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.616\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8, random_state=0)\n",
    "etr = etr = ExtraTreesClassifier()\n",
    "etr.fit(X_train, y_train)\n",
    "y_pred = etr.predict(X_test)\n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, y_pred),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# MLPClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8, random_state=0)\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "param_grid = {'solver': ['sgd', 'adam', 'lbfgs'],\n",
    "              'learning_rate': ['adaptive', \"constant\", \"invscaling\"],\n",
    "              }\n",
    "mlp_GS = GridSearchCV(mlp, param_grid=param_grid, cv=cv_train, verbose=True)\n",
    "mlp_GS.fit(X, y)\n",
    "print(mlp_GS.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.68689802\n",
      "Iteration 2, loss = 0.68524797\n",
      "Iteration 3, loss = 0.68453962\n",
      "Iteration 4, loss = 0.68426255\n",
      "Iteration 5, loss = 0.68396845\n",
      "Iteration 6, loss = 0.68365895\n",
      "Iteration 7, loss = 0.68351132\n",
      "Iteration 8, loss = 0.68333855\n",
      "Iteration 9, loss = 0.68324809\n",
      "Iteration 10, loss = 0.68302496\n",
      "Iteration 11, loss = 0.68291267\n",
      "Iteration 12, loss = 0.68273190\n",
      "Iteration 13, loss = 0.68281416\n",
      "Iteration 14, loss = 0.68262919\n",
      "Iteration 15, loss = 0.68249919\n",
      "Iteration 16, loss = 0.68253650\n",
      "Iteration 17, loss = 0.68229823\n",
      "Iteration 18, loss = 0.68225924\n",
      "Iteration 19, loss = 0.68210387\n",
      "Iteration 20, loss = 0.68202674\n",
      "Iteration 21, loss = 0.68200100\n",
      "Iteration 22, loss = 0.68194629\n",
      "Iteration 23, loss = 0.68189977\n",
      "Iteration 24, loss = 0.68181860\n",
      "Iteration 25, loss = 0.68168505\n",
      "Iteration 26, loss = 0.68164373\n",
      "Iteration 27, loss = 0.68173550\n",
      "Iteration 28, loss = 0.68168649\n",
      "Iteration 29, loss = 0.68157855\n",
      "Iteration 30, loss = 0.68143427\n",
      "Iteration 31, loss = 0.68142528\n",
      "Iteration 32, loss = 0.68125294\n",
      "Iteration 33, loss = 0.68128283\n",
      "Iteration 34, loss = 0.68131360\n",
      "Iteration 35, loss = 0.68118185\n",
      "Iteration 36, loss = 0.68123064\n",
      "Iteration 37, loss = 0.68124209\n",
      "Iteration 38, loss = 0.68110015\n",
      "Iteration 39, loss = 0.68116400\n",
      "Iteration 40, loss = 0.68107848\n",
      "Iteration 41, loss = 0.68092726\n",
      "Iteration 42, loss = 0.68090816\n",
      "Iteration 43, loss = 0.68105893\n",
      "Iteration 44, loss = 0.68090295\n",
      "Iteration 45, loss = 0.68081476\n",
      "Iteration 46, loss = 0.68073558\n",
      "Iteration 47, loss = 0.68065007\n",
      "Iteration 48, loss = 0.68066700\n",
      "Iteration 49, loss = 0.68077366\n",
      "Iteration 50, loss = 0.68064031\n",
      "Iteration 51, loss = 0.68053924\n",
      "Iteration 52, loss = 0.68049388\n",
      "Iteration 53, loss = 0.68056241\n",
      "Iteration 54, loss = 0.68040991\n",
      "Iteration 55, loss = 0.68053746\n",
      "Iteration 56, loss = 0.68034814\n",
      "Iteration 57, loss = 0.68046257\n",
      "Iteration 58, loss = 0.68032749\n",
      "Iteration 59, loss = 0.68038889\n",
      "Iteration 60, loss = 0.68035658\n",
      "Iteration 61, loss = 0.68034607\n",
      "Iteration 62, loss = 0.68019324\n",
      "Iteration 63, loss = 0.68035419\n",
      "Iteration 64, loss = 0.68020759\n",
      "Iteration 65, loss = 0.68034369\n",
      "Iteration 66, loss = 0.68027758\n",
      "Iteration 67, loss = 0.68026753\n",
      "Iteration 68, loss = 0.68028976\n",
      "Iteration 69, loss = 0.68036718\n",
      "Iteration 70, loss = 0.68006350\n",
      "Iteration 71, loss = 0.68016415\n",
      "Iteration 72, loss = 0.67994477\n",
      "Iteration 73, loss = 0.68014989\n",
      "Iteration 74, loss = 0.68006313\n",
      "Iteration 75, loss = 0.68011060\n",
      "Iteration 76, loss = 0.68018993\n",
      "Iteration 77, loss = 0.67997350\n",
      "Iteration 78, loss = 0.67988575\n",
      "Iteration 79, loss = 0.67990795\n",
      "Iteration 80, loss = 0.68015388\n",
      "Iteration 81, loss = 0.67983328\n",
      "Iteration 82, loss = 0.68001707\n",
      "Iteration 83, loss = 0.67987189\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Accuracy 0.557\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(norm_X, norm_y, train_size=.8, random_state=0)\n",
    "\n",
    "mlp = MLPClassifier(solver = \"adam\", learning_rate = \"adaptive\", max_iter = 1000, verbose = 3)\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_test)\n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "X_train, X_test, y_train, y_test = train_test_split(norm_X, norm_y, train_size=.8, random_state=0)\n",
    "\n",
    "gaussian = GaussianNB()\n",
    "param_grid={'var_smoothing': [1e-4, 1e-5, 1e-6, 1e-9]}\n",
    "gaussian_CV = GridSearchCV(estimator=gaussian, param_grid=param_grid, cv=cv_train, verbose=3)\n",
    "gaussian_CV.fit(X_train, y_train)\n",
    "print(gaussian_CV.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\Johnn\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:805 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\Johnn\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\Johnn\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Johnn\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Johnn\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Johnn\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:788 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\Johnn\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:754 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\Johnn\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\Johnn\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:255 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 7 but received input with shape (None, 16)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-178-4560333d867b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mnn_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_nn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    869\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 725\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    726\u001b[0m             *args, **kwds))\n\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2968\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2969\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2970\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3196\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 977\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    978\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\Johnn\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:805 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\Johnn\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\Johnn\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\Johnn\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\Johnn\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\Johnn\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:788 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\Johnn\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:754 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\Johnn\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\Johnn\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:255 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential is incompatible with the layer: expected axis -1 of input shape to have value 7 but received input with shape (None, 16)\n"
     ]
    }
   ],
   "source": [
    "# Thanks to https://www.kaggle.com/skrudals/modification-of-neural-network-around-90\n",
    "def build_nn(optimizer='adam'):\n",
    "\n",
    "    # Initializing the NN\n",
    "    nn = Sequential()\n",
    "\n",
    "    # Adding the input layer and the first hidden layer of the NN\n",
    "    nn.add(Dense(units=32, kernel_initializer='he_normal', activation='relu', input_shape=(len(X.columns),)))\n",
    "    # Adding the output layer\n",
    "    nn.add(Dense(units=1, kernel_initializer='he_normal', activation='sigmoid'))\n",
    "\n",
    "    # Compiling the NN\n",
    "    nn.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return nn\n",
    "\n",
    "Xtrain, Xval, Ztrain, Zval = train_test_split(norm_X, norm_y, test_size=0.2, random_state=0)\n",
    "nn_model = build_nn(optimizers.Adam(lr=0.0001))\n",
    "nn_model.fit(Xtrain, Ztrain, batch_size=16, epochs=15, validation_data=(Xval, Zval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN - 74% Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:   10.4s remaining:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   12.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'kd_tree', 'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8, random_state=0)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn_CV = GridSearchCV(estimator=knn, param_grid={'weights': ['distance'], \n",
    "                                                 'metric': ['manhattan', ], \n",
    "                                                 'algorithm': ['kd_tree'],\n",
    "                                                'n_neighbors': [5,7,9]}, \n",
    "                                    cv=cv_train, verbose=3, n_jobs = -1).fit(X, y)\n",
    "print(knn_CV.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.736\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8, random_state=0)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 10, weights='distance', metric = 'manhattan', algorithm = 'kd_tree')\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.741\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_other, y_other, train_size=.8, random_state=0)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 10, weights='distance', metric = 'manhattan', algorithm = 'kd_tree')\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.573\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_other1, y_other1, train_size=.8, random_state=0)\n",
    "\n",
    "knn = KNeighborsClassifier(weights='distance', metric = 'manhattan', algorithm = 'kd_tree')\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, y_pred),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.551\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8, random_state=0)\n",
    "\n",
    "sgd = SGDClassifier(loss = \"squared_loss\", early_stopping=True)\n",
    "sgd.fit(X, y)\n",
    "y_pred = sgd.predict(X_test)\n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, y_pred),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8, random_state=0)\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(objective='reg:squarederror') \n",
    "parameters = {'n_estimators': [50, 60, 70, 80, 90], \n",
    "              'learning_rate': [0.09, 0.1, 0.15, 0.2],\n",
    "              'max_depth': [3, 4, 5]}\n",
    "xgb_reg = GridSearchCV(estimator=xgb_clf, param_grid=parameters, cv=cv_train, verbose = 3).fit(X_train, y_train)\n",
    "print(\"Best score: %0.3f\" % xgb_reg.best_score_)\n",
    "print(\"Best parameters set:\", xgb_reg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.62\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8, random_state=0)\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    \n",
    "    objective='reg:squarederror') \n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(removed_X, removed_y, train_size=.8, random_state=0)\n",
    "\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(objective='reg:squarederror') \n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, y_pred),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(removed_X, removed_y, train_size=.8, random_state=0)\n",
    "modelL = lgb.LGBMClassifier(n_estimators=1000, num_leaves=40)\n",
    "modelL.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=50, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[3]\tvalid_0's binary_logloss: 0.683555\n",
      "[6]\tvalid_0's binary_logloss: 0.680702\n",
      "[9]\tvalid_0's binary_logloss: 0.678666\n",
      "[12]\tvalid_0's binary_logloss: 0.676996\n",
      "[15]\tvalid_0's binary_logloss: 0.676077\n",
      "[18]\tvalid_0's binary_logloss: 0.675144\n",
      "[21]\tvalid_0's binary_logloss: 0.674396\n",
      "[24]\tvalid_0's binary_logloss: 0.673838\n",
      "[27]\tvalid_0's binary_logloss: 0.673246\n",
      "[30]\tvalid_0's binary_logloss: 0.672697\n",
      "[33]\tvalid_0's binary_logloss: 0.672278\n",
      "[36]\tvalid_0's binary_logloss: 0.672083\n",
      "[39]\tvalid_0's binary_logloss: 0.671816\n",
      "[42]\tvalid_0's binary_logloss: 0.671494\n",
      "[45]\tvalid_0's binary_logloss: 0.671054\n",
      "[48]\tvalid_0's binary_logloss: 0.670732\n",
      "[51]\tvalid_0's binary_logloss: 0.670582\n",
      "[54]\tvalid_0's binary_logloss: 0.669913\n",
      "[57]\tvalid_0's binary_logloss: 0.66986\n",
      "[60]\tvalid_0's binary_logloss: 0.669141\n",
      "[63]\tvalid_0's binary_logloss: 0.668823\n",
      "[66]\tvalid_0's binary_logloss: 0.668871\n",
      "[69]\tvalid_0's binary_logloss: 0.668639\n",
      "[72]\tvalid_0's binary_logloss: 0.66829\n",
      "[75]\tvalid_0's binary_logloss: 0.668157\n",
      "[78]\tvalid_0's binary_logloss: 0.667851\n",
      "[81]\tvalid_0's binary_logloss: 0.667635\n",
      "[84]\tvalid_0's binary_logloss: 0.66762\n",
      "[87]\tvalid_0's binary_logloss: 0.667599\n",
      "[90]\tvalid_0's binary_logloss: 0.667313\n",
      "[93]\tvalid_0's binary_logloss: 0.667188\n",
      "[96]\tvalid_0's binary_logloss: 0.667143\n",
      "[99]\tvalid_0's binary_logloss: 0.666998\n",
      "[102]\tvalid_0's binary_logloss: 0.66655\n",
      "[105]\tvalid_0's binary_logloss: 0.666615\n",
      "[108]\tvalid_0's binary_logloss: 0.666385\n",
      "[111]\tvalid_0's binary_logloss: 0.666132\n",
      "[114]\tvalid_0's binary_logloss: 0.666048\n",
      "[117]\tvalid_0's binary_logloss: 0.665947\n",
      "[120]\tvalid_0's binary_logloss: 0.665604\n",
      "[123]\tvalid_0's binary_logloss: 0.665393\n",
      "[126]\tvalid_0's binary_logloss: 0.665294\n",
      "[129]\tvalid_0's binary_logloss: 0.664998\n",
      "[132]\tvalid_0's binary_logloss: 0.665011\n",
      "[135]\tvalid_0's binary_logloss: 0.664732\n",
      "[138]\tvalid_0's binary_logloss: 0.664618\n",
      "[141]\tvalid_0's binary_logloss: 0.664481\n",
      "[144]\tvalid_0's binary_logloss: 0.664407\n",
      "[147]\tvalid_0's binary_logloss: 0.664424\n",
      "[150]\tvalid_0's binary_logloss: 0.66428\n",
      "[153]\tvalid_0's binary_logloss: 0.66416\n",
      "[156]\tvalid_0's binary_logloss: 0.664251\n",
      "[159]\tvalid_0's binary_logloss: 0.664046\n",
      "[162]\tvalid_0's binary_logloss: 0.663935\n",
      "[165]\tvalid_0's binary_logloss: 0.663975\n",
      "[168]\tvalid_0's binary_logloss: 0.663628\n",
      "[171]\tvalid_0's binary_logloss: 0.66352\n",
      "[174]\tvalid_0's binary_logloss: 0.663329\n",
      "[177]\tvalid_0's binary_logloss: 0.663376\n",
      "[180]\tvalid_0's binary_logloss: 0.663091\n",
      "[183]\tvalid_0's binary_logloss: 0.663061\n",
      "[186]\tvalid_0's binary_logloss: 0.662801\n",
      "[189]\tvalid_0's binary_logloss: 0.662561\n",
      "[192]\tvalid_0's binary_logloss: 0.662542\n",
      "[195]\tvalid_0's binary_logloss: 0.662401\n",
      "[198]\tvalid_0's binary_logloss: 0.662391\n",
      "[201]\tvalid_0's binary_logloss: 0.662402\n",
      "[204]\tvalid_0's binary_logloss: 0.662333\n",
      "[207]\tvalid_0's binary_logloss: 0.662353\n",
      "[210]\tvalid_0's binary_logloss: 0.662073\n",
      "[213]\tvalid_0's binary_logloss: 0.661771\n",
      "[216]\tvalid_0's binary_logloss: 0.661692\n",
      "[219]\tvalid_0's binary_logloss: 0.661526\n",
      "[222]\tvalid_0's binary_logloss: 0.661102\n",
      "[225]\tvalid_0's binary_logloss: 0.660959\n",
      "[228]\tvalid_0's binary_logloss: 0.660809\n",
      "[231]\tvalid_0's binary_logloss: 0.660521\n",
      "[234]\tvalid_0's binary_logloss: 0.660586\n",
      "[237]\tvalid_0's binary_logloss: 0.660283\n",
      "[240]\tvalid_0's binary_logloss: 0.660348\n",
      "[243]\tvalid_0's binary_logloss: 0.660165\n",
      "[246]\tvalid_0's binary_logloss: 0.660133\n",
      "[249]\tvalid_0's binary_logloss: 0.660072\n",
      "[252]\tvalid_0's binary_logloss: 0.660108\n",
      "[255]\tvalid_0's binary_logloss: 0.65997\n",
      "[258]\tvalid_0's binary_logloss: 0.659837\n",
      "[261]\tvalid_0's binary_logloss: 0.659817\n",
      "[264]\tvalid_0's binary_logloss: 0.659843\n",
      "[267]\tvalid_0's binary_logloss: 0.65955\n",
      "[270]\tvalid_0's binary_logloss: 0.659359\n",
      "[273]\tvalid_0's binary_logloss: 0.659327\n",
      "[276]\tvalid_0's binary_logloss: 0.65913\n",
      "[279]\tvalid_0's binary_logloss: 0.659071\n",
      "[282]\tvalid_0's binary_logloss: 0.658944\n",
      "[285]\tvalid_0's binary_logloss: 0.65881\n",
      "[288]\tvalid_0's binary_logloss: 0.658834\n",
      "[291]\tvalid_0's binary_logloss: 0.65868\n",
      "[294]\tvalid_0's binary_logloss: 0.658549\n",
      "[297]\tvalid_0's binary_logloss: 0.65858\n",
      "[300]\tvalid_0's binary_logloss: 0.658605\n",
      "[303]\tvalid_0's binary_logloss: 0.658688\n",
      "[306]\tvalid_0's binary_logloss: 0.658683\n",
      "[309]\tvalid_0's binary_logloss: 0.658476\n",
      "[312]\tvalid_0's binary_logloss: 0.6583\n",
      "[315]\tvalid_0's binary_logloss: 0.658169\n",
      "[318]\tvalid_0's binary_logloss: 0.658176\n",
      "[321]\tvalid_0's binary_logloss: 0.658138\n",
      "[324]\tvalid_0's binary_logloss: 0.658068\n",
      "[327]\tvalid_0's binary_logloss: 0.658124\n",
      "[330]\tvalid_0's binary_logloss: 0.658054\n",
      "[333]\tvalid_0's binary_logloss: 0.658024\n",
      "[336]\tvalid_0's binary_logloss: 0.657975\n",
      "[339]\tvalid_0's binary_logloss: 0.657915\n",
      "[342]\tvalid_0's binary_logloss: 0.657884\n",
      "[345]\tvalid_0's binary_logloss: 0.65798\n",
      "[348]\tvalid_0's binary_logloss: 0.657858\n",
      "[351]\tvalid_0's binary_logloss: 0.65793\n",
      "[354]\tvalid_0's binary_logloss: 0.657939\n",
      "[357]\tvalid_0's binary_logloss: 0.657782\n",
      "[360]\tvalid_0's binary_logloss: 0.65768\n",
      "[363]\tvalid_0's binary_logloss: 0.657545\n",
      "[366]\tvalid_0's binary_logloss: 0.657483\n",
      "[369]\tvalid_0's binary_logloss: 0.657442\n",
      "[372]\tvalid_0's binary_logloss: 0.657529\n",
      "[375]\tvalid_0's binary_logloss: 0.657512\n",
      "[378]\tvalid_0's binary_logloss: 0.657555\n",
      "[381]\tvalid_0's binary_logloss: 0.65757\n",
      "[384]\tvalid_0's binary_logloss: 0.657674\n",
      "[387]\tvalid_0's binary_logloss: 0.657538\n",
      "[390]\tvalid_0's binary_logloss: 0.657429\n",
      "[393]\tvalid_0's binary_logloss: 0.657481\n",
      "[396]\tvalid_0's binary_logloss: 0.657486\n",
      "[399]\tvalid_0's binary_logloss: 0.657282\n",
      "[402]\tvalid_0's binary_logloss: 0.657284\n",
      "[405]\tvalid_0's binary_logloss: 0.657159\n",
      "[408]\tvalid_0's binary_logloss: 0.65711\n",
      "[411]\tvalid_0's binary_logloss: 0.657024\n",
      "[414]\tvalid_0's binary_logloss: 0.656822\n",
      "[417]\tvalid_0's binary_logloss: 0.656668\n",
      "[420]\tvalid_0's binary_logloss: 0.656588\n",
      "[423]\tvalid_0's binary_logloss: 0.656566\n",
      "[426]\tvalid_0's binary_logloss: 0.6565\n",
      "[429]\tvalid_0's binary_logloss: 0.656317\n",
      "[432]\tvalid_0's binary_logloss: 0.656244\n",
      "[435]\tvalid_0's binary_logloss: 0.65613\n",
      "[438]\tvalid_0's binary_logloss: 0.656043\n",
      "[441]\tvalid_0's binary_logloss: 0.655998\n",
      "[444]\tvalid_0's binary_logloss: 0.655885\n",
      "[447]\tvalid_0's binary_logloss: 0.655855\n",
      "[450]\tvalid_0's binary_logloss: 0.655821\n",
      "[453]\tvalid_0's binary_logloss: 0.655792\n",
      "[456]\tvalid_0's binary_logloss: 0.65569\n",
      "[459]\tvalid_0's binary_logloss: 0.655572\n",
      "[462]\tvalid_0's binary_logloss: 0.655581\n",
      "[465]\tvalid_0's binary_logloss: 0.655392\n",
      "[468]\tvalid_0's binary_logloss: 0.655253\n",
      "[471]\tvalid_0's binary_logloss: 0.655246\n",
      "[474]\tvalid_0's binary_logloss: 0.65502\n",
      "[477]\tvalid_0's binary_logloss: 0.655041\n",
      "[480]\tvalid_0's binary_logloss: 0.654893\n",
      "[483]\tvalid_0's binary_logloss: 0.654819\n",
      "[486]\tvalid_0's binary_logloss: 0.654782\n",
      "[489]\tvalid_0's binary_logloss: 0.654654\n",
      "[492]\tvalid_0's binary_logloss: 0.654675\n",
      "[495]\tvalid_0's binary_logloss: 0.654632\n",
      "[498]\tvalid_0's binary_logloss: 0.654725\n",
      "[501]\tvalid_0's binary_logloss: 0.654807\n",
      "[504]\tvalid_0's binary_logloss: 0.65481\n",
      "[507]\tvalid_0's binary_logloss: 0.654719\n",
      "[510]\tvalid_0's binary_logloss: 0.654732\n",
      "[513]\tvalid_0's binary_logloss: 0.654692\n",
      "[516]\tvalid_0's binary_logloss: 0.654647\n",
      "[519]\tvalid_0's binary_logloss: 0.654663\n",
      "[522]\tvalid_0's binary_logloss: 0.654637\n",
      "[525]\tvalid_0's binary_logloss: 0.654624\n",
      "[528]\tvalid_0's binary_logloss: 0.6545\n",
      "[531]\tvalid_0's binary_logloss: 0.65455\n",
      "[534]\tvalid_0's binary_logloss: 0.654481\n",
      "[537]\tvalid_0's binary_logloss: 0.654497\n",
      "[540]\tvalid_0's binary_logloss: 0.65463\n",
      "[543]\tvalid_0's binary_logloss: 0.654615\n",
      "[546]\tvalid_0's binary_logloss: 0.654586\n",
      "[549]\tvalid_0's binary_logloss: 0.654605\n",
      "[552]\tvalid_0's binary_logloss: 0.65453\n",
      "[555]\tvalid_0's binary_logloss: 0.654574\n",
      "[558]\tvalid_0's binary_logloss: 0.654426\n",
      "[561]\tvalid_0's binary_logloss: 0.654455\n",
      "[564]\tvalid_0's binary_logloss: 0.654462\n",
      "[567]\tvalid_0's binary_logloss: 0.654391\n",
      "[570]\tvalid_0's binary_logloss: 0.654306\n",
      "[573]\tvalid_0's binary_logloss: 0.654078\n",
      "[576]\tvalid_0's binary_logloss: 0.653971\n",
      "[579]\tvalid_0's binary_logloss: 0.653946\n",
      "[582]\tvalid_0's binary_logloss: 0.653864\n",
      "[585]\tvalid_0's binary_logloss: 0.653737\n",
      "[588]\tvalid_0's binary_logloss: 0.653778\n",
      "[591]\tvalid_0's binary_logloss: 0.653652\n",
      "[594]\tvalid_0's binary_logloss: 0.6537\n",
      "[597]\tvalid_0's binary_logloss: 0.653636\n",
      "[600]\tvalid_0's binary_logloss: 0.653579\n",
      "[603]\tvalid_0's binary_logloss: 0.65345\n",
      "[606]\tvalid_0's binary_logloss: 0.653447\n",
      "[609]\tvalid_0's binary_logloss: 0.653418\n",
      "[612]\tvalid_0's binary_logloss: 0.653404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[615]\tvalid_0's binary_logloss: 0.653368\n",
      "[618]\tvalid_0's binary_logloss: 0.653374\n",
      "[621]\tvalid_0's binary_logloss: 0.653348\n",
      "[624]\tvalid_0's binary_logloss: 0.653215\n",
      "[627]\tvalid_0's binary_logloss: 0.653177\n",
      "[630]\tvalid_0's binary_logloss: 0.653162\n",
      "[633]\tvalid_0's binary_logloss: 0.653176\n",
      "[636]\tvalid_0's binary_logloss: 0.653178\n",
      "[639]\tvalid_0's binary_logloss: 0.653208\n",
      "[642]\tvalid_0's binary_logloss: 0.653141\n",
      "[645]\tvalid_0's binary_logloss: 0.653142\n",
      "[648]\tvalid_0's binary_logloss: 0.653147\n",
      "[651]\tvalid_0's binary_logloss: 0.6532\n",
      "[654]\tvalid_0's binary_logloss: 0.653077\n",
      "[657]\tvalid_0's binary_logloss: 0.653112\n",
      "[660]\tvalid_0's binary_logloss: 0.653081\n",
      "[663]\tvalid_0's binary_logloss: 0.653036\n",
      "[666]\tvalid_0's binary_logloss: 0.652996\n",
      "[669]\tvalid_0's binary_logloss: 0.653066\n",
      "[672]\tvalid_0's binary_logloss: 0.653009\n",
      "[675]\tvalid_0's binary_logloss: 0.653007\n",
      "[678]\tvalid_0's binary_logloss: 0.653042\n",
      "[681]\tvalid_0's binary_logloss: 0.653129\n",
      "[684]\tvalid_0's binary_logloss: 0.653173\n",
      "[687]\tvalid_0's binary_logloss: 0.653243\n",
      "[690]\tvalid_0's binary_logloss: 0.653186\n",
      "[693]\tvalid_0's binary_logloss: 0.653204\n",
      "[696]\tvalid_0's binary_logloss: 0.653264\n",
      "[699]\tvalid_0's binary_logloss: 0.653321\n",
      "[702]\tvalid_0's binary_logloss: 0.653194\n",
      "[705]\tvalid_0's binary_logloss: 0.65323\n",
      "[708]\tvalid_0's binary_logloss: 0.653233\n",
      "[711]\tvalid_0's binary_logloss: 0.653249\n",
      "[714]\tvalid_0's binary_logloss: 0.653268\n",
      "[717]\tvalid_0's binary_logloss: 0.653243\n",
      "[720]\tvalid_0's binary_logloss: 0.653219\n",
      "[723]\tvalid_0's binary_logloss: 0.653169\n",
      "Early stopping, best iteration is:\n",
      "[673]\tvalid_0's binary_logloss: 0.652976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(n_estimators=10000, num_leaves=40)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8, random_state=0)\n",
    "modelL = lgb.LGBMClassifier(n_estimators=10000, num_leaves=40)\n",
    "modelL.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=50, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.615\n"
     ]
    }
   ],
   "source": [
    "y_pred = modelL.predict(X_test)\n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, y_pred),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.551\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8, random_state=0)\n",
    "\n",
    "log = LogisticRegression()\n",
    "log.fit(X_train, y_train)\n",
    "y_pred = log.predict(X_test)\n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contvar = df_model[['DP', 'VD', 'HIAF', 'IMPACT', 'sampleTimePt', 'gender', 'BIAS',\n",
    "       'REFBIAS', 'VARBIAS', 'QUAL', 'ODDRATIO', 'chipOrControl']]\n",
    "\n",
    "X_cont = df_contvar.drop('chipOrControl', axis = 1) \n",
    "y_cont = df_contvar['chipOrControl'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.639\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 0)\n",
    "\n",
    "# instantatiate the RFC with 100 ensemble members\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "Y_pred = clf.predict(X_test)  \n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, Y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP 0.31\n",
      "VD 0.066\n",
      "HIAF 0.153\n",
      "sampleTimePt 0.012\n",
      "gender 0.014\n",
      "REFBIAS 0.226\n",
      "ODDRATIO 0.218\n"
     ]
    }
   ],
   "source": [
    "for name, score in zip(X.columns, clf.feature_importances_):\n",
    "    print(name,np.round(score,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.682\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 0)\n",
    "\n",
    "# instantatiate the RFC with 100 ensemble members\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "Y_pred = dtc.predict(X_test)  \n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, Y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.692\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_other, y_other, train_size = 0.8, random_state = 0)\n",
    "\n",
    "# instantatiate the RFC with 100 ensemble members\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "Y_pred = dtc.predict(X_test)  \n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, Y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.692\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_other1, y_other1, train_size = 0.8, random_state = 0)\n",
    "\n",
    "# instantatiate the RFC with 100 ensemble members\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "Y_pred = dtc.predict(X_test)  \n",
    "print('Accuracy {0}'.format(np.round(accuracy_score(y_test, Y_pred),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_model\n",
    "target = 'chipOrControl'\n",
    "if \"Set\" not in train.columns:\n",
    "    train[\"Set\"] = np.random.choice([\"train\", \"valid\", \"test\"], p =[.8, .1, .1], size=(train.shape[0],))\n",
    "\n",
    "train_indices = train[train['Set'] == 1].index.array\n",
    "valid_indices = train[train['Set'] == 0].index.array\n",
    "test_indices = train[train['Set'] == 2].index.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampleTimePt 2\n",
      "gender 2\n",
      "chipOrControl 2\n",
      "Set 3\n"
     ]
    }
   ],
   "source": [
    "nunique = train.nunique()\n",
    "types = train.dtypes\n",
    "\n",
    "categorical_columns = []\n",
    "categorical_dims =  {}\n",
    "for col in train.columns:\n",
    "    if types[col] == 'object' or nunique[col] < 200:\n",
    "        print(col, train[col].nunique())\n",
    "        l_enc = LabelEncoder()\n",
    "        train[col] = train[col].fillna(\"VV_likely\")\n",
    "        train[col] = l_enc.fit_transform(train[col].values)\n",
    "        categorical_columns.append(col)\n",
    "        categorical_dims[col] = len(l_enc.classes_)\n",
    "    else:\n",
    "        train.fillna(train.loc[train_indices, col].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_feat = ['Set']\n",
    "\n",
    "features = [ col for col in train.columns if col not in unused_feat+[target]] \n",
    "\n",
    "cat_idxs = [ i for i, f in enumerate(features) if f in categorical_columns]\n",
    "\n",
    "cat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DP', 'VD', 'HIAF', 'sampleTimePt', 'gender', 'REFBIAS', 'ODDRATIO']\n",
      "[3, 4]\n",
      "[2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(features)\n",
    "print(cat_idxs)\n",
    "print(cat_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "clf = TabNetClassifier(cat_idxs=cat_idxs,\n",
    "                       cat_dims=cat_dims,\n",
    "                       cat_emb_dim=1,\n",
    "                       optimizer_fn=torch.optim.Adam,\n",
    "                       optimizer_params={'lr': 0.02},\n",
    "                       scheduler_params={\"step_size\":50, # how to use learning rate scheduler\n",
    "                                         \"gamma\":0.9},\n",
    "                       scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                       mask_type='entmax', # \"sparsemax\"\n",
    "                       verbose = 3\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[features].values[train_indices]\n",
    "y_train = train[target].values[train_indices]\n",
    "\n",
    "X_valid = train[features].values[valid_indices]\n",
    "y_valid = train[target].values[valid_indices]\n",
    "\n",
    "X_test = train[features].values[test_indices]\n",
    "y_test = train[target].values[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "max_epochs = 1000 if not os.getenv(\"CI\", False) else 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.719   | train_auc: 0.51637 | valid_auc: 0.51727 |  0:00:25s\n",
      "epoch 3  | loss: 0.6929  | train_auc: 0.53549 | valid_auc: 0.53889 |  0:01:25s\n",
      "epoch 6  | loss: 0.69175 | train_auc: 0.53639 | valid_auc: 0.54338 |  0:02:25s\n",
      "epoch 9  | loss: 0.69264 | train_auc: 0.53346 | valid_auc: 0.53563 |  0:03:21s\n",
      "epoch 12 | loss: 0.69243 | train_auc: 0.53473 | valid_auc: 0.53844 |  0:04:06s\n",
      "epoch 15 | loss: 0.69114 | train_auc: 0.52223 | valid_auc: 0.52391 |  0:04:46s\n",
      "epoch 18 | loss: 0.69042 | train_auc: 0.54065 | valid_auc: 0.54709 |  0:05:26s\n",
      "epoch 21 | loss: 0.69007 | train_auc: 0.54257 | valid_auc: 0.54478 |  0:06:06s\n",
      "epoch 24 | loss: 0.69037 | train_auc: 0.54477 | valid_auc: 0.54553 |  0:06:45s\n",
      "epoch 27 | loss: 0.69029 | train_auc: 0.53373 | valid_auc: 0.53883 |  0:07:26s\n",
      "epoch 30 | loss: 0.69078 | train_auc: 0.53879 | valid_auc: 0.54223 |  0:08:06s\n",
      "epoch 33 | loss: 0.69048 | train_auc: 0.53797 | valid_auc: 0.54237 |  0:08:47s\n",
      "epoch 36 | loss: 0.68963 | train_auc: 0.54032 | valid_auc: 0.53858 |  0:09:26s\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 18 and best_valid_auc = 0.54709\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "clf.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['auc'],\n",
    "    max_epochs=max_epochs , patience=20,\n",
    "    batch_size=1024, virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    weights=1,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a51d5cc250>]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD5CAYAAAAuneICAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAj1klEQVR4nO3deXhc9X3v8fdXMxp5ZmxkyZZXeQOMzW6wcEISwGEJjlsuS0iC21LS5oaShobkuTct5N7cS3OfphSahDxtEkoaArQphIQUuDcua8JSIMGy43jBK8bG8iLJluVFkrXMfO8fcyTGsmSNbGEN/n1ez6NHc878zug3Bzyf+S3n/MzdERGR8JQMdwVERGR4KABERAKlABARCZQCQEQkUAoAEZFAKQBERAIVL6SQmS0AvgPEgH9297t6Pf8V4A/zXvN0oApIAw8DE4AscL+7fyc6phL4CTAd2Ax8yt33HKkeY8eO9enTpxdSZRERiSxdunSXu1f13m8DXQdgZjFgPXAFUAcsARa5+5v9lL8K+LK7X2pmE4GJ7r7MzEYBS4Fr3P1NM7sbaHL3u8zsdqDC3f/qSHWpqanx2tragd+tiIj0MLOl7l7Te38hXUDzgI3uvsndO4BHgauPUH4R8AiAu+9w92XR4/3AGmByVO5q4KHo8UPANQXURUREhkghATAZ2Jq3Xce7H+KHMLMUsAB4vI/npgPnAb+Jdo139x2QCwpgXD+vebOZ1ZpZbWNjYwHVFRGRQhQSANbHvv76ja4CXnX3pkNewGwkuVD4krvvG0wF3f1+d69x95qqqsO6sERE5CgVEgB1wJS87Wpgez9lbyDq/ulmZqXkPvx/7O4/z3uqPhojIPrdUGilRUTk2BUSAEuAmWY2w8wS5D7kn+pdyMzKgUuAJ/P2GfBDYI27f6vXIU8BN0WPb8o/TkRE3nsDBoC7dwG3As+QG8R9zN1Xm9ktZnZLXtFrgWfdvSVv34eBG4FLzWx59LMweu4u4Aoz20BuhtEhU0tFROS9NeA00GKiaaAiIoN3LNNA3/deWFPP917cONzVEBEpKkEEwCsbdvFPL20a7mqIiBSVIAIgmYjR1pEZ7mqIiBSVIAIgnYjRkcnSmckOd1VERIpGEAGQTOTuedeqVoCISI8gAiCdiAHQ2tE1zDURESkeQQRAMgqAlna1AEREugURAOmoC0gDwSIi7woiAFLdLQB1AYmI9AgjAMrUAhAR6S2IAEirBSAicpggAiDZMwtILQARkW5BBED3IHBru1oAIiLdggiAnhZAp1oAIiLdggiAsngJsRKjVdcBiIj0CCIAzIxUaUyDwCIieYIIAIBUme4IKiKSL5gASCfitCgARER6BBMAuTUB1AUkItItmABIJ+K6GZyISJ5gAiCZiGkaqIhInmACIF0W04VgIiJ5ggmAZGlct4IQEckTTACky2JaEUxEJE8wAZBMxDQNVEQkT0EBYGYLzGydmW00s9v7eP4rZrY8+lllZhkzq4yee8DMGsxsVa9j7jSzbXnHLRyat9S3dCJOR1eWrkz2vfwzIiLvGwMGgJnFgO8CHwfOABaZ2Rn5Zdz9Hnef4+5zgDuAl9y9KXr6QWBBPy//7e7j3H3xUb6HgqR0QzgRkUMU0gKYB2x0903u3gE8Clx9hPKLgEe6N9z9ZaCp/+LHR0rrAouIHKKQAJgMbM3brov2HcbMUuS+7T9e4N+/1cxWRN1EFf285s1mVmtmtY2NjQW+7OHSZdGqYJoKKiICFBYA1sc+76fsVcCred0/R/J94BRgDrAD+GZfhdz9fnevcfeaqqqqAl62b8lSrQomIpKvkACoA6bkbVcD2/spewN53T9H4u717p5x9yzwA3JdTe+ZdLQwvAJARCSnkABYAsw0sxlmliD3If9U70JmVg5cAjxZyB82s4l5m9cCq/orOxSSWhheROQQAwaAu3cBtwLPAGuAx9x9tZndYma35BW9FnjW3VvyjzezR4DXgVlmVmdmn42eutvMVprZCuCjwJeH4P30K61BYBGRQ8QLKRRN0Vzca999vbYfJDfls/exi/p5zRsLreRQ6J4GqkFgEZGcYK4E7g6ANl0HICICBBQA3YPAWhNARCQnmAAoi5dghlYFExGJBBMAZqZ1gUVE8gQTABCtCqYWgIgIEFgApBMxXQgmIhIJKgCSWhheRKRHUAGQTsRo61QXkIgIBBYAqTK1AEREuoUVAKUx3QpCRCQSVgCUxXQzOBGRSFgBoFlAIiI9ggqAdCKu6wBERCJBBUAyEeNgZ5ZMtr8FzUREwhFUAPSsCaA7goqIhBUAqWhh+FatCSAiElgAJLQwvIhIt8ACIFoTQAPBIiKhBUC0KphaACIioQVAdwtAASAiElgAaBBYRKRbUAHQPQ1Ug8AiIoEFQLJnFpBaACIiQQVAukzTQEVEugUVACPiMcw0CCwiAgUGgJktMLN1ZrbRzG7v4/mvmNny6GeVmWXMrDJ67gEzazCzVb2OqTSz58xsQ/S7YmjeUv9KSoxkaYw2dQGJiAwcAGYWA74LfBw4A1hkZmfkl3H3e9x9jrvPAe4AXnL3pujpB4EFfbz07cAL7j4TeCHafs+lEnG1AEREKKwFMA/Y6O6b3L0DeBS4+gjlFwGPdG+4+8tAUx/lrgYeih4/BFxTSIWPVSoR0zRQEREKC4DJwNa87bpo32HMLEXu2/7jBbzueHffARD9HtfPa95sZrVmVtvY2FjAyx6ZFoUREckpJACsj3393VD/KuDVvO6fY+bu97t7jbvXVFVVHfPrKQBERHIKCYA6YEredjWwvZ+yN5DX/TOAejObCBD9bijwuGOSLtOqYCIiUFgALAFmmtkMM0uQ+5B/qnchMysHLgGeLPBvPwXcFD2+aRDHHRO1AEREcgYMAHfvAm4FngHWAI+5+2ozu8XMbskrei3wrLu35B9vZo8ArwOzzKzOzD4bPXUXcIWZbQCuiLbfc6lEXAEgIgLECynk7ouBxb323ddr+0FyUz57H7uon9fcDVxWYD2HTK4FoC4gEZGgrgSGXAC0tKsFICISYADEaevMkM32N5FJRCQMAQZAtCpYp1oBIhK28AKgTGsCiIhAiAFQqjUBREQgwADQmgAiIjnBBUCqZ1lItQBEJGwBBoBaACIiEGQA5FoAuhZAREIXYABoEFhEBEIMAA0Ci4gAIQaABoFFRIAAAyBZqhaAiAgEGACxEiNZqjUBRESCCwDQLaFFRCDUACiL0appoCISuDADoDROi1oAIhK4MAOgTGMAIiJhBoAWhhcRCTUAtDC8iEigAaBZQCIigQaAWgAiIkEGQDoRo7VdLQARCVuQAZBKxGjtzODuw10VEZFhU1AAmNkCM1tnZhvN7PY+nv+KmS2PflaZWcbMKo90rJndaWbb8o5bOHRv68hSZXHc4WBn9nj9SRGRojNgAJhZDPgu8HHgDGCRmZ2RX8bd73H3Oe4+B7gDeMndmwo49tvdx7n74qF5SwPrXhNAF4OJSMgKaQHMAza6+yZ37wAeBa4+QvlFwCNHeexx0X1L6DYNBItIwAoJgMnA1rztumjfYcwsBSwAHi/w2FvNbIWZPWBmFf285s1mVmtmtY2NjQVUd2BqAYiIFBYA1se+/kZPrwJedfemAo79PnAKMAfYAXyzrxd09/vdvcbda6qqqgqo7sC0MLyISGEBUAdMyduuBrb3U/YG3u3+OeKx7l7v7hl3zwI/INdddFyky6JVwXRHUBEJWCEBsASYaWYzzCxB7kP+qd6FzKwcuAR4spBjzWxiXrlrgVVH9xYG791VwdQFJCLhig9UwN27zOxW4BkgBjzg7qvN7Jbo+fuiotcCz7p7y0DHRk/fbWZzyHUJbQb+bGje0sB6WgDqAhKRgA0YAADRFM3Fvfbd12v7QeDBQo6N9t84iHoOKQ0Ci4gEfCUwaBqoiIQt0ADINXxaNAgsIgELMgBiJUZZvITWTnUBiUi4ggwAiG4IpxaAiAQs4ADQmgAiErZgAyBdplXBRCRswQZAMhGnRS0AEQlYsAGQTsRoUwtARAIWbACkEjFNAxWRoAUcAHHaOhUAIhKugAMgRosWhheRgAUcAHHdCkJEghZsAKTLYrR0dOHe39o2IiIntmADIJmIkXVo78oOd1VERIZFsAGQTmhNABEJW7ABkOxeE0ADwSISqGADoLsFoKmgIhKqYAMgpRaAiAQu+ADQVFARCVXAARCtCqYAEJFAhRsAZbkWgG4JLSKhCjYANA1UREIXbABoGqiIhC7YANAgsIiELtgAKI2VkIiVaBBYRIJVUACY2QIzW2dmG83s9j6e/4qZLY9+VplZxswqj3SsmVWa2XNmtiH6XTF0b6swqTKtCiYi4RowAMwsBnwX+DhwBrDIzM7IL+Pu97j7HHefA9wBvOTuTQMcezvwgrvPBF6Ito+rVGlMLQARCVYhLYB5wEZ33+TuHcCjwNVHKL8IeKSAY68GHooePwRcM8i6H7NUmdYEEJFwFRIAk4Gtedt10b7DmFkKWAA8XsCx4919B0D0e1w/r3mzmdWaWW1jY2MB1S1cOpFbE0BEJESFBID1sa+/VVSuAl5196ajOLZP7n6/u9e4e01VVdVgDh1QMhHTdQAiEqxCAqAOmJK3XQ1s76fsDbzb/TPQsfVmNhEg+t1QSIWHUjoR15XAIhKsQgJgCTDTzGaYWYLch/xTvQuZWTlwCfBkgcc+BdwUPb6p13HHRTIRo7VdLQARCVN8oALu3mVmtwLPADHgAXdfbWa3RM/fFxW9FnjW3VsGOjZ6+i7gMTP7LPAO8MmhelOFyrUAFAAiEqYBAwDA3RcDi3vtu6/X9oPAg4UcG+3fDVxWeFWHXlKDwCISsGCvBAZIl8Vo68jgPqhxaRGRE0LQAZBKxOnKOh2Z7HBXRUTkuAs8AHRDOBEJV9ABkNaqYCISsKADoHtNgFatCSAiAQo6ANI9y0KqBSAi4Qk6AJKl3V1AagGISHiCDoDuFoAGgUUkREEHQPcsIA0Ci0iIAg+AXBeQVgUTkRAFHQA900B1QzgRCVDQAdA9DbStUwEgIuEJOgAS8RJKY0aLrgMQkQAFHQAAyVKtCiYiYQo+ANJlWhVMRMIUfADk1gRQC0BEwhN8AKQTcV0IJiJBCj4AkomYBoFFJEjBB0A6EdM0UBEJUvABkCqLqwUgIkFSAGgaqIgEKvgAyE0DVQCISHiCD4BkIqbrAEQkSMEHQDoRozPjdHRlh7sqIiLHVUEBYGYLzGydmW00s9v7KTPfzJab2Wozeylv/21mtira/6W8/Xea2bbomOVmtvCY381RSPbcElrdQCISlvhABcwsBnwXuAKoA5aY2VPu/mZemdHA94AF7v6OmY2L9p8FfA6YB3QAT5vZL9x9Q3Tot93974fyDQ1Wunth+M4uyikdzqqIiBxXhbQA5gEb3X2Tu3cAjwJX9yrzB8DP3f0dAHdviPafDvza3VvdvQt4Cbh2aKo+NFJlWhNARMJUSABMBrbmbddF+/KdBlSY2YtmttTM/jjavwq42MzGmFkKWAhMyTvuVjNbYWYPmFnFUb6HY5IqjVoAGggWkcAUEgDWxz7vtR0H5gK/B1wJfM3MTnP3NcDfAc8BTwO/A7o/ab8PnALMAXYA3+zzj5vdbGa1Zlbb2NhYQHUHJ1XWHQBqAYhIWAoJgDoO/dZeDWzvo8zT7t7i7ruAl4FzAdz9h+5+vrtfDDQBG6L99e6ecfcs8ANyXU2Hcff73b3G3WuqqqoG894K0r0usFoAIhKaQgJgCTDTzGaYWQK4AXiqV5kngYvMLB519XwAWAOQNyA8FbgOeCTanph3/LXkuouOu55BYLUARCQwA84CcvcuM7sVeAaIAQ+4+2ozuyV6/j53X2NmTwMrgCzwz+7e/YH+uJmNATqBL7j7nmj/3WY2h1x30mbgz4bwfRWse13gVg0Ci0hgBgwAAHdfDCzute++Xtv3APf0cexF/bzmjYVX872TVheQiAQq+CuBu1sAWhVMREITfACUxUuIlZiuBBaR4AQfAGZGKhGjRV1AIhKY4AMAIJWIaRBYRIKjACA3ENyqZSFFJDAKAKI1AbQspIgERgFA1ALQILCIBEYBgFYFE5EwFXQh2IkuXRZje/PgWgDNrR2sqNvLym17+d3WZva2dXLmpHLOqS7n7OpyZoxJU1LS1330RESKgwIASJbG2dvWydqd+3r2WXQTVIs+w5taOlhR18yKur2sqNvLO02tPWVPHpumPFXKv72xhQdezS0tOaoszlmTc4FwTvVoLphewbiTRhy/NzVImawTU2CJBEUBAFSmS2nY386Ce18ZsOzk0UnOqS5n0bypnFtdzpmTyylP5lYS68pk2dBwgJV1e1mxLRcWD7z6Np0Zpyxewv+55iw+VTNlgL9wfL2zu5X/8cRKXntrN2dOOokLpldGPxWMGVk23NUTkfeQufe+tX/xqqmp8dra2iF/3b2tnby+aTfgdJ+O7rPSvZ0ui3HW5HLGDvJDsb0rw9od+/m7p9fy2lu7+VRNNV+/+ixGRAvRDJeuTJYfvbqZbz63jnhJCdeeN5l19ftZvrWZjq5cK+bUcSO5YHol82ZUcMH0SiaPTmJWeCvB3Vm7cz+/XNvAgfYuvvDRUxlZpu8cIsebmS1195rD9isAjo9M1rn3+fX8wy83MnvCKL7/R3OZMTY9LHVZtW0vd/x8JSu37eXy08fx9avPYtLoJJALrJV1e3ljcxNL3m6idvMe9kdTZCecNIK50yuomVZBzbRKTp84injs0HkEBzszvPbWLl5Y08Cv1jawfe9BINeVdsbEk3jgMxcwvoi7wkRORAqAIvGrdQ18+SfL6co4d19/DgvPnjjwQUPkYGeGe5/fwA9e2URFKsFf/5czWXj2hCN+q89knbU791G7eQ+1W/awdHNTz4d6KhFjzpTR1EyroDKd4OUNu3h14y7au7KkEjE+cupYLjt9HPNnjePNHfu49cfLKE+W8qM/mcesCaOO19sWCZ4CoIhsa27jCz9exvKtzXzmQ9P56sLTScTf2xm5r23cxR3/vpItu1v5dM0UvrrwdMpTpUf1Wtub23rCoHbLHtbs2EfWYWpliktnj+PS2eP4wMmVlMUP7eZavX0vf/rgElrbM9x341w+fOrYoXhrIjIABUCR6ejK8rf/sYYfvbqZOVNG861PncuYdG58waMRiPz/NLGYMTIRH3BqaTbr1O1pY+3OfazbuZ919ftZt3M/GxoOMH1Mim9cdzYfOmVoP3gPtHexp6WD6oqBxwi2N7fxJz9awluNB7jrE+dw/dzqIa2LiBxOAVCkFq/cwV/+bAUHCrgVRYnBqBGllCdLOSkZpzwZPR5RStaddfUH2FC//5CrmqdWpjht/ChqplfwmQ9NH/bBZ4B9Bzv5839dxn9u3MVtl83kS5fPHNTgsogMjgKgiL2zu5UX1tb3fOPP/yzsftiZcfYd7GRfWyd7e/3sO9iFO5w2fiSzJoxi1vhRzJowitPGjyJdpLNuOjNZ7vj5Sn62tI5PnF/N31539nveDSYSqv4CoDg/HQIzdUyKP/nwjOGuxnFVGivhnuvPYWplim89t5519fs4a1I5FekElakEFekEFanSnu2xo8o0hVRkiOlflAwbM+OLl81kamWK+156ixfWNtDc2kFnpu9WaWU6wdTKFNPHpJg6Js30MSmmjUkxbUyaMemEupGkX+6u/z/6oC4gKSruHg0qd9LU2sGelg72tHbQsL+dLbtb2bK7hS27W9m+t+2QQfIx6QRXnTuJ6+dWc+akk/SPXYDcpIjvvbiR7/7qLT59wRRuu2wmFenEcFfruNMYgJxQ2rsy1O1pY8vuFjbvamXplj0892Y9HZkssyeM4vq51Vxz3uRBX7ktJ469rZ18+bHl/HJtA+dOGc3KumZGlsX54mUz+eMLpwc15qQAkBNec2sH/3fFDn62tI7fbW0mXmLMnzWO6+dWc+nscSfsP/hM1tmyu4WplanDrswudtmss3r7Ppa9s4eDnRm6sk5XxunKZqPHud+JWAnXnj+Z2RNOKuh1V23byy3/upT6fQf5X79/Bn/0wWlsaDjA3/xiDS+tb2TamBR3fHw2V5555AshTxQKAAnKhvr9/GxZHT9fto3G/e1UphN8+oIp/OEHplJdkRqyv+Pu7DrQwe6WdlKlcUaNyP0crw/i5tYO/uKR3/LKhl1UpEr56OxxXHH6eC46rapoB82bWjp4ZUMjL61r5OUNjew60HFYGTMoLSkhVmLEY8bBzgydGefS2eP4/PxTuGB6Zb+v/5Ml7/C1J1czJp3ge394PudNrTjk+RfXNfCNxWtYX3+AeTMq+drvncHZ1eVD/j6LiQJAgtSVyfLKxl088pt3eH5NPQCXzh7PH184jY+cOragNRsOdmZ4q/EAW5ta2drUxtY9rbnHe9qo29PKwc7sYcckS2OMHNEdCKWMG1XGwrMnsODMiSQTQ3Mtxvr6/Xzu4Vq2N7fx+fmnUtfUyi/XNdDc2kkiVsKFp4zh8jPGc/np45hYnhySvzlY7s6+g11sbDjAy+sbeWl9I7+ra8YdKlKlXHxaFfNnVXHhyWM5KRknVmKUlpQc9t+lubWDh1/fwoOvbaappYO50yr4/CWncOnscT1lD3Zm+NoTq/jp0joumjmWez89p9872nZlsvykdivfenY9u1s6uPa8yXz6ginUTKt437WiCnFMAWBmC4DvADHgn939rj7KzAfuBUqBXe5+SbT/NuBz5Ka0/8Dd7432VwI/AaYDm4FPufueI9VDASDHYltzG//2my08+sZWdrd0MGNsmj/64DSun1vdc0vvA+1dvLl9H6u27WXV9r28uX0fGxoOkMm+++9kVFmc6soUUyqSTIl+jx1VRltHhv0Hu9h/sIsD7Z09j/cd7GRTYwvbmtsYWRZn4dkT+MT51cybUXnU3Q/Prt7Jl3+ynGQizj/deD5zp+W+EXdlsizdsofn19Tz3Jv1bN6dW7fi7MnlXHPeZK6ZM2nIb/Pd1pFhRV0z25rb2N7cxrbmg2xvbmPH3ja2Nx/sucjRDM6tHs38WVXMnzWOsyeXD3oNiraODI/VbuX+lzexrbmNmeNGcsslp3DulNF88ZHf8uaOfXzx0lO57fLTCnrt/Qc7+d6Lb/HAf75Ne1eWynSCy2aP48ozJ/CRmWOL4sLJoXDUAWBmMWA9cAVQBywBFrn7m3llRgOvAQvc/R0zG+fuDWZ2FvAoMA/oAJ4GPu/uG8zsbqDJ3e8ys9uBCnf/qyPVRQEgQ6G9K8N/rNzJw69vZtk7zSRLY3zw5Eo2727l7V0tPeXGjizjrMkncdakcmZPHMW0yjRTKpOUJ0sH/cGdzTpvbG7i8aV1LF65g5aODFMqk3zi/Go+cX41UyoL65bKZp1/+OVGvv38es6pLuefbpzb77d7d+etxhaeX1PP4pU7WFG3l9KYcenscXxy7hTmz6o6qm+73bf5fmVDIy+v38Ubm5t6biEOuRlZk0YnmVg+gkmjk0wenWRKZZIPzBgzZDNwOjNZfrFiB99/8S3W1e8HoDxZyrc/fS6Xzh4/6Nc70N7Fy+sbeWb1Tn65toH9B7tIJWJccloVV545gY/OHtfzJeF4yWad/e1dPRd/Th2T4qQRR1eHYwmAC4E73f3KaPsOAHf/27wyfw5Mcvf/2evYTwJXuvt/jba/BrS7+91mtg6Y7+47zGwi8KK7zzpSXRQAMtRWbdvLv7y+hdotTZw6biRnTSrnzOhD/71awa21o4unV+3k8WV1vPbWbtzhgukVXDSzig+ePIZzp5QfdiM9gJb2Lv7bY7/j6dU7ue68yXzjurMH9Q113c79/LR2K08s38auAx2MHVnGdedP5pNzq5k5vv+7s7o7u1s6eHXjLl5ev4tXNjTSsL8dyF19fvHMKj506himj0kzaXTyuH5rdndeXNfI82vqueWSUwoO0iPp6Mry6027eWb1Tp57s77nvZbFS0gmYqRKY7nfiTjJ6HF5spT5s6r42JkTBjX2cqC9i2dW5UJnd0s7+9q6oqv7OznQ3nXIVOeH/nQel5xWdVTv6VgC4Hpy3+y7P8RvBD7g7rfmlbmXXNfPmcAo4Dvu/rCZnQ48CVwItAEvALXu/hdm1uzuo/NeY4+7Hzpak9t/M3AzwNSpU+du2bJlUG9cpJhta27j35fVsXjlTtbs3Id77oNm7rQKPnjymJ5AqN/bzucermVDw36+uvB0PvuRGUfdfdSZyfKrtQ38dGkdv1rbQFfWOW38SBLxEg52ZmnvytDemaW9K3rcle35IBqdKuUjp47l4tOquGjm2GEbWzhesllneV0zr23cxf6DXbR2ZGjrzNAW/W7t6KKtI8POfQep39fOiNISLj99PNfMmczFp1X1OfOsoyvLy+sbeWL5Np5fU8/BziwTy0cwpSLFSck4J40o5aRk9DMiHt37q5Tzp1ZQNerouu+OJQB6f4u/EZjn7n+RV+YfgRrgMiAJvA78nruvN7PPAl8ADgBvAm3u/uVCAyCfWgByImtu7eCNt5v49aYmfr1pd08gjCgtIR7NiPnHPziPi2Ye3bfAvuw60M4Tv93GKxt2ES8xykpLKIvHKIuXMKI097ssXsLIEXE+MGMMZx1Fv30I3J2lW/bw5PLt/L8V29nT2snoVCkLz57INXMmM3daBcve2cMTv93GL1buoLm1k4pUKb9/ziSunjOJudMq3tPpqO91F9DtwAh3vzPa/iHwtLv/tNdrfQOoc/fvqQtI5MiaWzv4zdu5MGjc385//9gspg/TKnJSuM5Mllc2NPLk8u08u7qets4MI0pzrasRpSV87IwJXHPeJC6aWUXpcZpxdCwBECc3CHwZsI3cIPAfuPvqvDKnA/8IXAkkgDeAG9x9Vd6A8FTgWeBCd99jZvcAu/MGgSvd/S+PVBcFgIi8n7S0d/Hcm/X85u3dzJtRycfOmDAsd+g96ruBunuXmd0KPENuGugD7r7azG6Jnr/P3deY2dPACiBLbqroquglHjezMUAn8IW8qZ53AY9FXUTvAJ88xvcoIlJU0mXx3PTb8yYPd1X6pAvBREROcP21AE68S95ERKQgCgARkUApAEREAqUAEBEJlAJARCRQCgARkUApAEREAvW+ug7AzBqBo70b3Fhg1xBWZ6ipfsdG9Ts2qt+xK+Y6TnP3w24i9b4KgGNhZrV9XQhRLFS/Y6P6HRvV79i9H+rYm7qAREQCpQAQEQlUSAFw/3BXYACq37FR/Y6N6nfs3g91PEQwYwAiInKokFoAIiKSRwEgIhKoIALAzBaY2Toz2xitPlZUzGyzma00s+VmNuwLHpjZA2bWYGar8vZVmtlzZrYh+n3E9ZuHoX53mtm26BwuN7OFw1i/KWb2KzNbY2arzey2aH9RnMMj1K8ozqGZjTCzN8zsd1H9/jraXyznr7/6FcX5G4wTfgzAzGLklrS8Aqgjt6TlInd/c1grlsfMNgM17l4UF5GY2cXAAeBhdz8r2nc30JS3hGeFu/9VEdXvTuCAu//9cNQpX7TG9UR3X2Zmo4ClwDXAZyiCc3iE+n2KIjiHllsdPe3uB8ysFPhP4DbgOorj/PVXvwUUwfkbjBBaAPOAje6+yd07gEeBq4e5TkXN3V8Gmnrtvhp4KHr8ELkPjGHRT/2KhrvvcPdl0eP9wBpgMkVyDo9Qv6LgOQeizdLoxyme89df/d53QgiAycDWvO06iuh/9ogDz5rZUjO7ebgr04/x7r4Dch8gwLhhrk9fbjWzFVEX0bB1UeUzs+nAecBvKMJz2Kt+UCTn0MxiZrYcaACec/eiOn/91A+K5PwVKoQAsD72FVtaf9jdzwc+Dnwh6uKQwfk+cAowB9gBfHNYawOY2UjgceBL7r5vuOvTWx/1K5pz6O4Zd58DVAPzzOys4apLX/qpX9Gcv0KFEAB1wJS87Wpg+zDVpU/uvj363QD8O7luq2JTH/Udd/chNwxzfQ7h7vXRP8os8AOG+RxGfcOPAz92959Hu4vmHPZVv2I7h1GdmoEXyfWvF83565Zfv2I8fwMJIQCWADPNbIaZJYAbgKeGuU49zCwdDcRhZmngY8CqIx81LJ4Cbooe3wQ8OYx1OUz3B0PkWobxHEaDhD8E1rj7t/KeKopz2F/9iuUcmlmVmY2OHieBy4G1FM/567N+xXL+BuOEnwUEEE3HuheIAQ+4+98Mb43eZWYnk/vWDxAH/m2462dmjwDzyd3eth7438ATwGPAVOAd4JPuPiwDsf3Ubz65prcDm4E/6+4vHob6fQR4BVgJZKPdXyXXzz7s5/AI9VtEEZxDMzuH3CBvjNyX1Mfc/etmNobiOH/91e9fKILzNxhBBICIiBwuhC4gERHpgwJARCRQCgARkUApAEREAqUAEBEJlAJARCRQCgARkUD9f+hRAsHXqYE+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(clf.history['loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a5205b0a30>]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot auc\n",
    "plt.plot(clf.history['train_auc'])\n",
    "plt.plot(clf.history['valid_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a52054d400>]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot learning rates\n",
    "plt.plot(clf.history['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST VALID SCORE FOR CHIP Validation : 0.5470927621565707\n",
      "FINAL TEST SCORE FOR CHIP Validation : 0.5373497142927846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "preds = clf.predict_proba(X_test)\n",
    "test_auc = roc_auc_score(y_score=preds[:,1], y_true=y_test)\n",
    "\n",
    "\n",
    "preds_valid = clf.predict_proba(X_valid)\n",
    "valid_auc = roc_auc_score(y_score=preds_valid[:,1], y_true=y_valid)\n",
    "\n",
    "print(f\"BEST VALID SCORE FOR CHIP Validation : {clf.best_cost}\")\n",
    "print(f\"FINAL TEST SCORE FOR CHIP Validation : {test_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
